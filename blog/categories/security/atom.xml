<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Security | Kamranicus]]></title>
  <link href="http://kamranicus.com/blog/categories/security/atom.xml" rel="self"/>
  <link href="http://kamranicus.com/"/>
  <updated>2016-08-11T23:31:31+00:00</updated>
  <id>http://kamranicus.com/</id>
  <author>
    <name><![CDATA[Kamran]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Adding Subresource Integrity Support to Cassette .NET]]></title>
    <link href="http://kamranicus.com/blog/2016/05/08/cassette-subresource-integrity-sri/"/>
    <updated>2016-05-08T05:13:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/05/08/cassette-subresource-integrity-sri</id>
    <content type="html"><![CDATA[<p>If you aren&rsquo;t familiar with <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity">Subresource Integrity</a>, it&rsquo;s a browser-based security measure to protect embedded content like scripts and stylesheets using a file content hash to help protect against XSS attacks.</p>

<p>For example, let&rsquo;s say you&rsquo;re including a script from a CDN:</p>

<pre><code>&lt;script src="https://mycdn.com/jquery/1.0/jquery.js"&gt;&lt;/script&gt;
</code></pre>

<p>Then let&rsquo;s say the CDN is compromised and instead of returning jquery, the script returns some malicious code that could compromise your site. Even if you&rsquo;re using Content Security Policy (CSP), you won&rsquo;t be protected because you whitelisted the CDN.</p>

<p>Subresource Integrity allows you to put a hash of the file&rsquo;s contents in an attribute of the tag. The browser will then hash the contents of the response from the CDN and compare it against the attribute provided. If the hashes don&rsquo;t match, the browser won&rsquo;t include the response and will throw an error.</p>

<pre><code>&lt;script src="https://mycdn.com/jquery/1.0/jquery.js" integrity="sha256-hfhsh02929fhgh303yg"&gt;&lt;/script&gt;
</code></pre>

<h2>Integrating with Cassette</h2>

<p>I use <a href="http://getcassette.net">Cassette</a> to perform my bundling/minification and I also <a href="http://kamranicus.com/blog/2015/10/10/azure-cdn-cassette/">host my assets on a CDN</a>. Even though they are my own assets, I still want to ensure they are served securely and take advantage of SRI.</p>

<p>For third-party scripts, it is fairly easy to take advantage of SRI by <a href="https://srihash.org/">hashing the contents online</a> and customizing the CDN reference in Cassette:</p>

<pre><code>bundles.AddUrl("http://mycdn.com/jquery/1.0/jquery.js", bundle =&gt;
    bundle.HtmlAttributes.Add("integrity", "sha256-jquerysfilehash"));
</code></pre>

<p>But since my <em>own</em> files are dynamic, how can we still leverage Cassette <em>and</em> automatically hash the file contents when outputting to the page?</p>

<p>Luckily, Cassette is pretty extensible and includes a way to <a href="http://getcassette.net/documentation/v2/bundle-pipelines">customize the bundle pipeline</a>. So what we can do is essentially override the rendering of the HTML and add the <code>integrity</code> tag to the output.</p>

<p>To make this easy, I&rsquo;ve created an open source Nuget package called <a href="https://github.com/kamranayub/cassette-sri">Cassette.SubresourceIntegrity</a>. All you do is install the package and <strong>that&rsquo;s it.</strong> Since Cassette automatically scans for bundle customizations, all I did was implement a class <code>InsertIntoPipelineSubresourceIntegrity</code> and modify the pipeline to replace a couple parts with SRI-aware code.</p>

<p>The meat of the change is this code here:</p>

<pre><code>string integrity;

using (var stream = asset.OpenStream())
{
    using (var sha256 = SHA256.Create())
    {
        integrity = $"integrity=\"sha256-{Convert.ToBase64String(sha256.ComputeHash(stream))}\"";
    }
}

return $"&lt;script src=\"{_urlGenerator.CreateAssetUrl(asset)}\" " +
       $"type=\"text/javascript\" " +
       $"{integrity}{bundle.HtmlAttributes.ToAttributeString()}&gt;&lt;/script&gt;";
</code></pre>

<p>I am just getting the asset stream and hashing the contents using SHA256, then adding the attribute to the output. You&rsquo;ll notice that the <strong>URLs are not changed</strong>, so Cassette will continue to use SHA1 hashes internally. It&rsquo;s <em>only when rendering</em> we use SHA256 because that&rsquo;s the only place we need it.</p>

<p>While the code is interesting, it&rsquo;s nothing too crazy&mdash;in fact, most of the code required is because Cassette doesn&rsquo;t expose certain needed classes used in the rendering pipeline so I had to basically copy/paste a lot of the helper classes.</p>

<h2>The end result</h2>

<p>Now Cassette will automatically include SRI hashes for individual assets:</p>

<pre><code>&lt;link href="cassette.axd/asset/Content/bootstrap/bootstrap-ext.css?cabc6264a89106c4b9021c293cfa5c2cae7a0549" 
    integrity="sha256-sNfA6O5zvZPmMJ474pm2w6UyZbz5tfukxTEZXrsLm7Q=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/asset/Content/modules/typeahead.css?00581b47ff3848da273d91c31adb8270e9ef8707" 
    integrity="sha256-W6JAiwRw2ER1QoXjXL/YxsY/On1Y7MhW4TtoWY0XuH8=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/asset/Content/modules/toastr.css?32e90a136e05728ac23995ff8fe33077df9f50ca" 
    integrity="sha256-JT6UwDlczdRDx+9mnMCzvxwABJP0cSDgNLmT+WumJrQ=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/asset/Content/hopscotch/hopscotch.css?58ea04e54df958c33cf9e6bfed9f39a166354e9c" 
    integrity="sha256-Bq06LI6L0XMhxF+CoJo+4L12w2Orsbh2oRjOZ+fpmWc=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/asset/Content/core.css?a3b4fcb8b7d9b0e8465a4fea29d60247ea47fd87" 
    integrity="sha256-fAqyFLkOx1cFONu7NXX3c7/G1DSmXeHgtPtcWU72a4E=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/asset/Content/library.css?2c2746a086737dc588e313c0cc2c5adf8b947605" 
    integrity="sha256-SaP9kdYfbafIVes+qntAiDLPsi4JaXnit4eN6IfU9lA=" type="text/css" rel="stylesheet"/&gt;
</code></pre>

<p><em>and</em> bundles:</p>

<pre><code>&lt;link href="cassette.axd/stylesheet/ba58f2a04873e41b6a599274ea6768db1a61a650/Content/core" 
    integrity="sha256-thzkrIApz9dAI9nfJGleO1jbNFXXVT/BxoSynI2pEPw=" type="text/css" rel="stylesheet"/&gt;
&lt;link href="cassette.axd/stylesheet/2c2746a086737dc588e313c0cc2c5adf8b947605/Content/library.css" 
    integrity="sha256-6LgYbxu4UwouRBqvUdHZAQc0lewdik6aZYpDgrtAWJ4=" type="text/css" rel="stylesheet"/&gt;
</code></pre>

<p>Voila!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Generating an Encryption Certificate for PowerShell DSC in WMF5]]></title>
    <link href="http://kamranicus.com/blog/2016/04/05/wmf5-powershell-dsc-generating-encryption-certificate/"/>
    <updated>2016-04-05T03:43:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/04/05/wmf5-powershell-dsc-generating-encryption-certificate</id>
    <content type="html"><![CDATA[<p>I&rsquo;m currently building out a PowerShell DSC pull server cluster at work. If you aren&rsquo;t familiar with DSC, I&rsquo;ll talk more about it in an upcoming post that ties it all together. The long and short of it is that DSC is a way to store configuration as code and automate the configuration of many servers at once.</p>

<p>In the recent Windows Management Framework 5 release, Microsoft has improved its support and feature set for DSC but with a new release comes new surprises. The first surprise you may run into, as we did, was that your old WMF4 way of encrypting MOF files doesn&rsquo;t work. In WMF5, the requirements for the certificate used to secure MOF files is stricter. <a href="https://msdn.microsoft.com/en-us/powershell/dsc/securemof">Taken from MSDN</a>:</p>

<ol>
<li>Key Usage:</li>
<li>Must contain: &lsquo;KeyEncipherment&rsquo; and &lsquo;DataEncipherment&rsquo;.</li>
<li>Should <em>not</em> contain: &lsquo;Digital Signature&rsquo;.</li>
<li>Enhanced Key Usage:</li>
<li>Must contain: Document Encryption (1.3.6.1.4.1.311.80.1).</li>
<li>Should <em>not</em> contain: Client Authentication (1.3.6.1.5.5.7.3.2) and Server Authentication (1.3.6.1.5.5.7.3.1).</li>
</ol>


<p>If you read my <a href="http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure/">previous foray into certificates with Azure Key Vault</a>, you know I&rsquo;m pretty green when it comes to certificate management and terminology. I really didn&rsquo;t know what this stuff meant&mdash;I mean, I understand a certificate has key usages and enhanced key usages, but <strong>how does it get them?</strong> It has to do with the certificate request and the template used to provision your certificate.</p>

<p>It turns out Microsoft recommends obtaining a certificate from Active Directory Certificate Services. That&rsquo;s cool, but I&rsquo;m just a developer who wants to work on DSC, I don&rsquo;t have an ADCS server to give me certificates during testing&mdash;that&rsquo;s a different team altogether and when they&rsquo;re primary guy is out of the office, I&rsquo;m a bit stuck.</p>

<p><strong>Update (4/13)</strong>: <a href="https://msdn.microsoft.com/en-us/powershell/dsc/securemof">TechNet</a> now has a guide on how to generate certificates for WMF5. I&rsquo;m leaving the rest of this post as-is for posterity.</p>

<hr />

<p>I thought I could maybe use a self-signed certificate while I wait for a &ldquo;for real&rdquo; one later. After searching around for a method to create a certificate with the required KU and EKU specs, I found a lot of answers suggesting using OpenSSL. I&rsquo;ve never used OpenSSL before so I thought I&rsquo;d give it a try and I found it a bit confusing&mdash;I think I could have gotten it to work but instead I came across a random PowerShell article (unrelated to anything) using a utility called <code>certreq</code> that could handle providing custom key usages, problem solved!</p>

<p>You just need to create a file to define your certificate settings, <strong>MyCert.inf</strong>:</p>

<p>```
[Version]
Signature = &ldquo;$Windows NT$&rdquo;</p>

<p>[Strings]
szOID_ENHANCED_KEY_USAGE = &ldquo;2.5.29.37&rdquo;
szOID_DOCUMENT_ENCRYPTION = &ldquo;1.3.6.1.4.1.311.80.1&rdquo;</p>

<p>[NewRequest]
Subject = &ldquo;cn=<a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#x6f;&#x3a;&#109;&#x65;&#x40;&#x65;&#120;&#x61;&#109;&#x70;&#x6c;&#x65;&#x2e;&#x63;&#x6f;&#109;">&#109;&#x65;&#x40;&#101;&#120;&#97;&#x6d;&#x70;&#x6c;&#x65;&#x2e;&#99;&#111;&#109;</a>&rdquo;
MachineKeySet = false
KeyLength = 2048
KeySpec = AT_KEYEXCHANGE
HashAlgorithm = Sha1
Exportable = true
RequestType = Cert</p>

<p>KeyUsage = &ldquo;CERT_KEY_ENCIPHERMENT_KEY_USAGE | CERT_DATA_ENCIPHERMENT_KEY_USAGE&rdquo;
ValidityPeriod = &ldquo;Years&rdquo;
ValidityPeriodUnits = &ldquo;1000&rdquo;</p>

<p>[Extensions]
%szOID_ENHANCED_KEY_USAGE% = &ldquo;{text}%szOID_DOCUMENT_ENCRYPTION%&rdquo;
```</p>

<p>Just change the <code>Subject</code> line to whatever you need in your case.</p>

<p>Then execute <code>certreq</code> using the input file:</p>

<pre><code>certreq -new MyCert.inf MyCert.cer
</code></pre>

<p>Certreq should be available if you have Makecert&mdash;if you aren&rsquo;t finding it in the default command prompt, try using the Visual Studio Command Prompt. Once you execute the command it will generate a public key file and install the private/public key pair into your <code>CurrentUser</code> personal certificate store:</p>

<pre><code>PS&gt; dir Cert:\CurrentUser\My
</code></pre>

<p>From there, you can export the private/public keys and install it on your DSC nodes.</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/14269791/dac55acc-fa9c-11e5-8352-55881c3150ed.png" alt="Example screenshot" /></p>

<p>Until you get a signed certificate from your CA, this should work. Hope that helps!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Handling Multiple Origins in CORS Using URL Rewrite]]></title>
    <link href="http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis/"/>
    <updated>2016-03-06T15:50:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis</id>
    <content type="html"><![CDATA[<p>Here&rsquo;s a quick tip if you&rsquo;re trying to figure out how to handle <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">cross-origin requests (CORS)</a> when you have multiple origins (namely, HTTP and HTTPS). This works in IIS 8.0 and above, including Azure, as long as you have the <a href="http://www.iis.net/downloads/microsoft/url-rewrite">URL Rewrite module</a> installed.</p>

<p>The CORS header looks like this:</p>

<p><code>
Access-Control-Allow-Origin: http://mydomain.com
</code></p>

<p>The spec is very strict. The header can only return a single value and it must be absolutely qualified, which means if you have a site that is served over HTTP and HTTPS (or multiple domains), you need to <em>dynamically</em> build this header in your response. Many tutorials and blog posts say to specify <code>*</code> as the value&mdash;<strong>DO NOT DO THIS!</strong> This means any origin (domain) can embed/request assets from your website. Unless you have hundreds of sites doing this (aka CDN), you should only whitelist the domains that can include resources from your site.</p>

<p>If you are sharing resources with a known number of hosts, the following method will help. If it&rsquo;s a <em>dynamic</em> list, you will need to programmatically add the <code>Access-Control-Allow-Origin</code> header depending on the incoming <code>Origin</code> header&mdash;something I won&rsquo;t cover here.</p>

<p>Rather than messing with C# and modifying outgoing responses what I ended up using was a simple URL rewrite rule, proposed by <a href="http://stackoverflow.com/a/31084390/109458">this Stack Overflow answer</a>. All it does is add a header to the outbound response when the regular expression matches&mdash;in this case, whitelisting only the HTTP and HTTPS version of my domain (or subdomain).</p>

<p>```
&lt;system.webServer>
   <httpProtocol></p>

<pre><code> &lt;customHeaders&gt;
     &lt;add name="Access-Control-Allow-Headers" value="Origin, X-Requested-With, Content-Type, Accept" /&gt;
     &lt;add name="Access-Control-Allow-Methods" value="POST,GET,OPTIONS,PUT,DELETE" /&gt;
 &lt;/customHeaders&gt;
</code></pre>

<p>   </httpProtocol>
   <rewrite></p>

<pre><code>  &lt;outboundRules&gt;
      &lt;clear /&gt;                
      &lt;rule name="AddCrossDomainHeader"&gt;
          &lt;match serverVariable="RESPONSE_Access_Control_Allow_Origin" pattern=".*" /&gt;
          &lt;conditions logicalGrouping="MatchAll" trackAllCaptures="true"&gt;
              &lt;add input="{HTTP_ORIGIN}" pattern="(http(s)?:\/\/((.+\.)?mydomain\.com))" /&gt;
          &lt;/conditions&gt;
          &lt;action type="Rewrite" value="{C:0}" /&gt;
      &lt;/rule&gt;           
  &lt;/outboundRules&gt;
</code></pre>

<p>   </rewrite>
&lt;/system.webServer>
```</p>

<p>This is using special syntax of the URL Rewrite module (<code>RESPONSE_</code>) to add a outgoing response header (dashes replaced with underscores). Then it matches the <em>incoming</em> <code>Origin</code> header, compares the value, and if it matches includes the CORS header with the value of my domain.</p>

<p>That was all I had to do!</p>

<p><strong>Note:</strong> Since I just converted over to always SSL, I no longer need this workaround but multiple origins is pretty common when dealing with CORS so this solution will come in handy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Securing Secrets Using Azure Key Vault and Config Encryption]]></title>
    <link href="http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure/"/>
    <updated>2016-02-24T02:30:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure</id>
    <content type="html"><![CDATA[<p>Secrets. We all have them. I&rsquo;m talking about secrets like your database connection strings, API keys and encryption keys. Where are you storing yours? Are you storing them&hellip;</p>

<ol>
<li>In your application&rsquo;s source code?</li>
<li>In a config file (<code>appSettings</code> or otherwise) checked into source control?</li>
<li>In a database?</li>
<li>In a managed portal, like Azure?</li>
</ol>


<p>I hope you aren&rsquo;t storing them hardcoded. You&rsquo;re probably doing option 2 or a hybrid of options 2-4. Even if you use an external data source, it&rsquo;s hard to escape the need for secrets in local development unless you force your app to rely on having connectivity which makes it hard to work offline.</p>

<p>In this post I&rsquo;m going to provide some suggestions on how to store your secrets better using Azure Key Vault and config file encryption, specifically in the context of Azure but the concepts apply to any hosting environment.</p>

<!-- More -->


<h2>Why bother?</h2>

<p>Some of you might say, &ldquo;It&rsquo;s okay if my secret is in a config file or an environment variable, only an admin can see that.&rdquo; You&rsquo;d assume so, wouldn&rsquo;t you? But I ran into an exploit last year where you could view <strong>ANY</strong> file on the web server using a custom file handler vulnerability (the exploit has since been fixed by the vendor). Just pass in the path you cared about and the handler would helpfully spit out the contents of the file! If your secrets are in cleartext in your configs, are you checking them into source control? Anyone can read those if they have access. If you work in an organization and your code is on the web servers, anyone with access to those servers can see the file system (and therefore, your precious &ldquo;secrets&rdquo;).</p>

<p>You might also (rightfully) say that if an attacker got access to your Azure portal, it&rsquo;s game over anyway. Yes, absolutely. If an app is compromised at the filesystem level where an attacker can upload files, you&rsquo;re pretty much done for. That&rsquo;s why your portal account should have a strong password and have Two-Factor Authentication enabled. If you&rsquo;re using source control integration, that also needs to be protected with the same amount of security to prevent someone from checking in malicious files and having them deployed through automation to the web server&mdash;go and <a href="https://help.github.com/articles/about-two-factor-authentication/">enable TFA for GitHub</a> if you haven&rsquo;t already.  The goal is that we want to avoid storing plaintext secrets on the filesystem and in the portal itself, instead opting to store them in a secure location so that only <strong>our application</strong> has access to them, no one else.</p>

<p>There are more benefits to separating your secrets from your application:</p>

<ul>
<li><strong>Logging</strong> &mdash; Azure Key Vault logs all operations, so if someone did compromise your application, you&rsquo;d have the logs or could monitor them closely for strange actions</li>
<li><strong>Least privilege</strong> &mdash; You can grant a service principal Read-only access so even if the app was compromised, an attacker couldn&rsquo;t change or delete anything (unless they also had access to change the policies in Key Vault)</li>
<li><strong>As-needed access</strong> &mdash; By storing secrets away from your application, you at <em>least</em> guarantee only the application can access secrets whereas anyone with Read access to the portal can see app settings</li>
<li><strong>Defense in depth</strong> &mdash; You&rsquo;re just adding one more layer of security between an attacker and your data</li>
<li><strong>Shared storage</strong> &mdash; If you have multiple apps or services, using a single vault is useful and you can grant access policies at the secret or key level</li>
<li><strong>Encrypted configs</strong> &mdash; Instead of storing secrets in cleartext in source control, I will show you how to encrypt sections of your web.config (and it works in Azure!)</li>
<li><strong>Right thing to do</strong> &mdash; You owe it to your users and to your business to protect their data to the best of your ability</li>
</ul>


<p><a href="http://blogs.msdn.com/b/data_insights_global_practice/archive/2015/09/24/protecting-sensitive-data-with-azure-key-vault.aspx">This article</a> sums it up nicely:</p>

<blockquote><p>One of the key security principals that is implicitly being applied here is to compartmentalize management of privileged data to security domains for which this is appropriate. An instance of Key Vault is used to manage the Twitter keys as a shared resource in the customer&rsquo;s environment, with access granted by whomever manages the Twitter account on an as-needed basis to specific applications and users. Applications are then responsible for managing only their application-specific Key Vault access tokens.</p></blockquote>

<p>With that in mind, let&rsquo;s move on!</p>

<h2>Encryption keys</h2>

<p>The most important secret in your app is probably your <strong>encryption key</strong> (aka &ldquo;keys&rdquo;). This is the skeleton key to your kingdom. If someone got ahold of it, they could unlock your user&rsquo;s data and tarnish your reputation. If your Azure or portal account was compromised (even after Two Factor Auth), would attackers have access to your keys? They would if you stored them in a config or in the portal. So how can you protect this key if none of the options above truly secure it?</p>

<p>Well, what if I told you that <strong>you don&rsquo;t need to know the key</strong>. If nobody knows it, no one can steal it! But how does that work exactly? Magic? Not exactly&hellip;</p>

<h2>Welcome to the vault</h2>

<p>Enter <a href="https://azure.microsoft.com/en-us/services/key-vault/">Azure Key Vault</a>.</p>

<p>Azure Key Vault does two things:</p>

<ul>
<li>It stores encryption &ldquo;keys&rdquo; which <strong>you cannot retrieve</strong> so that you can encrypt and decrypt data, you&rsquo;d use this for user data like PII (Personally Identifiable Information)</li>
<li>It stores &ldquo;secrets&rdquo; which <strong>you can</strong> retrieve, these are things like passwords, API tokens, or other items you pass around</li>
</ul>


<p>A word about how Azure Key Vault stores keys. It&rsquo;s basically the most hardcore thing ever. If you opt for the Premium service tier, your key is stored on <strong>dedicated hardware</strong> called a Hardware Security Module (HSM). I had never heard of these so let me clue you in: they are <strong><a href="https://en.wikipedia.org/wiki/Hardware_security_module">devices</a></strong> where all they do is encrypt and decrypt data and never let the key leave their boundaries. That means, essentially, you present the data you want to encrypt to the device, it encrypts it using a key that <strong>nobody knows</strong>, and spits out the ciphertext for you to store in your system. Azure Key Vault also supports <em>software-protected</em> keys which can operate under the same conditions except they are not stored on a dedicated device. The HSM is validated to be <a href="https://en.wikipedia.org/wiki/FIPS_140-2#Level_2">FIPS 140-2 Level 2</a> compliant (out of 4 levels). What does that mean exactly?</p>

<p>Well, here&rsquo;s Level 1 security:</p>

<blockquote><p>Level 1 provides the lowest level of security. Basic security requirements are specified for a cryptographic module (e.g., at least one Approved algorithm or Approved security function shall be used). No specific physical security mechanisms are required in a Security Level 1 cryptographic module beyond the basic requirement for production-grade components. An example of a Security Level 1 cryptographic module is a personal computer (PC) encryption board.</p></blockquote>

<p>OK, so we&rsquo;re still talking <strong>a dedicated encryption board</strong> to secure keys&hellip; how about Level 2?</p>

<blockquote><p>Security Level 2 improves upon the physical security mechanisms of a Security Level 1 cryptographic module by requiring features that show evidence of tampering, including tamper-evident coatings or seals that must be broken to attain physical access to the plaintext cryptographic keys and critical security parameters (CSPs) within the module, or pick-resistant locks on covers or doors to protect against unauthorized physical access.</p></blockquote>

<p>Jeez. That means there are <em>physical defenses</em> in place on the device to prevent intrusion. We&rsquo;re not even talking intrusion through the network, no, literally these devices are secured so a <strong>human being</strong> cannot access them. Even if it&rsquo;s not Level 4, that&rsquo;s still <em>way</em> more secure than in your App.config or your database or web portal. And even Wikipedia admits that &ldquo;<a href="https://en.wikipedia.org/wiki/Hardware_security_module#Security">very few</a>&rdquo; HSMs are Level 4 validated.</p>

<p>You&rsquo;d think this hardcore security would be pricey right? Not at all. I think the <a href="https://azure.microsoft.com/en-us/pricing/details/key-vault/">$1/key/mo</a> price tag is pretty fair considering the security offered.</p>

<h2>What about secrets?</h2>

<p>OK. So Azure Key Vault is a pretty good solution to our encryption key problem. What about generic secrets, stuff you will need to pass within your application or to external services? Azure Key Vault supports that without any trouble, though they won&rsquo;t be stored on dedicated hardware. They will still be stored separately from your application behind lock and key which is our ultimate goal.</p>

<h2>But even a safe needs a combination, won&rsquo;t the <em>vault</em> require a key?</h2>

<p>Yes! And you are right to point out that it doesn&rsquo;t really solve the secrets problem if the key I need to use to unlock the vault is <em>also</em> stored in my app.config or portal or database. Luckily, there&rsquo;s a way to solve that!</p>

<h2>Certificates to the rescue</h2>

<p>Instead of using the default authentication to Azure AD, a &ldquo;client ID&rdquo; and &ldquo;secret token&rdquo;, we will actually provide a secure X.509 certificate that we&rsquo;ll upload to Azure. Since you can&rsquo;t download the certificate from Azure or access the private key, it will authenticate your application without exposing the key to your vault in a config or portal interface.</p>

<h2>Let&rsquo;s do it!</h2>

<p>I followed these two guides for setting up Key Vault and authenticating using a certificate, so I won&rsquo;t repeat the steps here but I do have several notes below that augment the guides:</p>

<ol>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-get-started/">Getting Started with Azure Key Vault</a></li>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-use-from-web-application">Using Azure Key Vault from a Web Application</a></li>
</ol>


<p>Follow the appendix in guide 2 to generate a certificate to authenticate to Azure AD.</p>

<p>As you work through the guides, reference the notes below.</p>

<h3>PowerShell Cmdlet Changes</h3>

<p>For guide 2, in Azure SDK 2.8+, the cmdlets have changed now:</p>

<ul>
<li><code>New-AzureADApplication</code> is now <code>New-AzureRmADApplication</code></li>
<li><code>New-AzureADServicePrincipal</code> is now <code>New-AzureRmADServicePrincipal</code></li>
</ul>


<p>When executing <code>Set-AzureKeyVaultAccessPolicy</code> make sure to add the switch <code>-PermissionsToSecrets all</code> to grant permissions to manage secrets.</p>

<p><strong>Note:</strong> The article tells you to grant <code>all</code> permissions to both keys and secrets. In reality, for production, you may want to only grant specific rights. See <a href="https://msdn.microsoft.com/en-us/library/dn903607.aspx">this MSDN article</a> for the different access policies.</p>

<h3>Certificates&hellip;?</h3>

<p>If you&rsquo;re like me, you probably find certificates can be confusing. Are you making an SSL cert? Not exactly. <em>Most</em> SSL certs are X.509 certs (not all) but they also can be used to encrypt web traffic. &ldquo;Plain&rdquo; X.509 certs can be used to sign things or encrypt/authenticate, which is what we&rsquo;re doing. If you Google around, you&rsquo;ll see they can be called &ldquo;client certificates&rdquo; or &ldquo;personal&rdquo; certificates. There are two places a cert can be installed (&ldquo;stores&rdquo;), one is the &ldquo;Local Machine&rdquo; store and the other is the &ldquo;Current User&rdquo; store. The machine store can be accessed by <em>any</em> user account, the current user store can only be accessed by the user running the process (usually, you). A &ldquo;cer&rdquo; file is the <strong>public key</strong> for your certificate. You can distribute it to anyone. The &ldquo;pfx&rdquo; file contains <strong>both the private AND public key</strong>. <strong>DO NOT GIVE IT TO ANYONE.</strong> You want the PFX file for yourself only and to import into your PC and into Azure. The PFX file is protected by a password, I recommend a strong one and <em>don&rsquo;t lose it.</em> Rule of thumb: <strong>NEVER let the private key leave your machine. This means don&rsquo;t email it. Yes, this has really happened before.</strong></p>

<h3>Certificate key length</h3>

<p>In guide 2, you create a self-signed certificate. For production should you use a commercially-signed cert? I can&rsquo;t think of a reason why that would add any extra benefit since the <strong>key length</strong> is what matters (if you <em>can</em> think of a reason, I&rsquo;d be interested in hearing it). What I <em>would</em> recommend is generating a certificate with a 4096-bit length key instead of the default 2048 length. In Windows 10 at least, this works:</p>

<p><code>
makecert -sv mykey.pvk -n "cn=KVWebApp" KVWebApp.cer -b 02/23/2016 -e 02/23/2018 -len 4096 -r
</code></p>

<p>If you live in fear, you can buy &ldquo;personal&rdquo; certs from trusted authorities like <a href="https://ssl.comodo.com/personal-authentication.php">Comodo</a> and use that instead.</p>

<h3>Install the certificate</h3>

<p>For guide 2, after generating the certificate you need to install it locally to test Azure Key Vault. If you run your app under IIS and the app pool is <code>ApplicationPoolIdentity</code>, it&rsquo;s best to just <a href="http://www.iis.net/learn/manage/configuring-security/application-pool-identities">change it</a> to run under your account. Trust me, it&rsquo;ll be easier. Since Azure requires the certificate to be in the <code>CurrentUser</code> store, the default app pool runs under a different account (see <a href="http://stackoverflow.com/a/3176253/109458">this StackOverflow post</a>), so you&rsquo;d have to install the cert at the machine level.</p>

<p>In the folder where your cert was generated, right-click the <code>.pfx</code> file and select Install. Enter the password you chose. You can also <a href="http://www.databasemart.com/howto/SQLoverssl/How_To_Import_Personal_Certificate_With_MMC.aspx">follow this guide</a> to do it from the MMC console.</p>

<h2>Alright, so what about local secrets?</h2>

<p>We have the cloud secrets squared away. You <em>could</em> still use Key Vault locally, except you&rsquo;d depend on connectivity (and pay for the usage). Instead, there&rsquo;s something we can do even if we don&rsquo;t end up using Azure Key Vault. We can <strong>encrypt the settings</strong> in the web.config.</p>

<p>I started with <a href="http://eren.ws/2014/02/04/encrypting-the-web-config-file-of-an-azure-cloud-service">this guide</a> to encrypting the configuration sections (but <strong>NOT</strong> <code>appSettings</code>, see below). You <strong>cannot</strong> use the same certificate you generated in the tutorial above (well, maybe you could but you need the <code>-exchange sky</code> switch to <code>makecert</code> and I didn&rsquo;t try that initially so I generated a separate certificate).</p>

<p>There&rsquo;s another thing. You also need to use a different <code>PKCS12ProtectedConfigurationProvider</code>. The one provided <strong>only</strong> searches the <code>LocalMachine</code> certificate store but in Azure, your cert is installed for the current user, so the provider fails to decrypt the config when you try to build your app on Azure because it cannot find the certificate. You need a provider that can specify the <code>StoreLocation</code> of where to load certificates from. For Azure, it must be the <strong>CurrentUser</strong> store.</p>

<p>Here&rsquo;s my modified version:</p>

<script src="https://gist.github.com/kamranayub/eaf4c4e4983ecb2d0b37.js"></script>


<p>I&rsquo;ve also added it to <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider">GitHub</a>. You can download the DLL directly from <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider/releases/tag/v1.0.1">GitHub</a>. Once done, you can change the entry in the config to:</p>

<p>```</p>

<pre><code>&lt;configProtectedData&gt;
    &lt;providers&gt;
        &lt;add name="CustomProvider"
             thumbprint="xxx"
             storeLocation="LocalMachine"
             type="Pkcs12ProtectedConfigurationProvider.Pkcs12ProtectedConfigurationProvider, PKCS12ProtectedConfigurationProvider, Version=1.0.1.0, Culture=neutral, PublicKeyToken=455a6e7bdbdc9023" /&gt;
    &lt;/providers&gt;
&lt;/configProtectedData&gt;
</code></pre>

<p>```</p>

<p>A few notes:</p>

<ol>
<li>This <strong>is not</strong> the same certificate you generated for Azure AD and Key Vault. This is a separate RSA certificate for use with configuration encryption. You must <em>also</em> upload the PFX for this to Azure.</li>
<li>You will need to install the PKCS12ProtectedConfigurationProvider.dll to the GAC before running the <code>aspnet_regiis</code> command. Just run <code>gacutil -i PKCS12ProtectedConfigurationProvider.dll</code> beforehand.</li>
<li>You will need to reference the custom compiled DLL instead of the one in the guide</li>
<li>I found <a href="http://stackoverflow.com/questions/17189441/web-config-encryption-for-web-sites">this StackOverflow question</a> which asks about encrypting the web.config for Azure web apps. Using the PKCS12 provider, <strong>it works.</strong></li>
</ol>


<h3>Storing secrets outside <code>&lt;appSettings&gt;</code></h3>

<p>I ran into a major hurdle that caused me some grief. It turns out, <strong>YOU CANNOT ENCRYPT THE <code>&lt;appSettings&gt;</code> SECTION!</strong> See <a href="http://stackoverflow.com/questions/15067759/why-cant-i-encrypt-web-config-appsettings-using-a-custom-configprotectionprovid">this SO question</a>.</p>

<p>Other sections are just fine but for whatever reason, IIS just <strong>requires</strong> you to GAC the config provider for it to work. In Azure web apps, we cannot GAC. So what can we do? We can use our <strong>own</strong> config section!</p>

<p>Here&rsquo;s an implementation example of an <code>ISecretsProvider</code> contract and a <code>ConfigSecretsProvider</code> example implementation. You&rsquo;d also create an <code>AzureKeyVaultSecretsProvider</code> probably to handle getting secrets from Azure Key Vault using the code from the guides above.</p>

<script src="https://gist.github.com/kamranayub/eb6518356ac2b2f1a72a.js"></script>


<p>The <code>ConfigSecretsProvider</code> will use environment variables defined in Azure <em>first</em> then fallback to the config. This mirrors how app settings work in Azure.</p>

<p><strong>Note:</strong> Here I am deciding to use only one provider per environment. You might want an implementation that actually uses both. My Key Vault implementation actually uses the <code>ConfigSecretsProvider</code> to find the URL to load the secret for, so that in Azure, the app settings just specify the Key Vault secret URL to load:</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/13271735/9a0f600a-da5c-11e5-9ff0-106d5e009464.png" alt="App settings in Azure" /></p>

<p>This way, locally I can use the raw value (encrypted) and then in Azure, reference the URL for the secret.</p>

<p>To encrypt the <code>&lt;appSecrets&gt;</code> section, just run the the command (in the same directory as the web.config and using the Visual Studio Command Prompt):</p>

<p><code>
aspnet_regiis -pef appSecrets . -prov CustomProvider
</code></p>

<p>And to decrypt:</p>

<p><code>
aspnet_regiis -pdf appSecrets .
</code></p>

<p>Easy peasy!</p>

<h2>So where are we at?</h2>

<p>If you followed all the guides I linked to and followed the notes, you should have the following:</p>

<ol>
<li>An Azure Key Vault set up with a secret to test with</li>
<li>A certificate that authenticates against Azure AD</li>
<li>A certificate that can encrypt/decrypt your web.config</li>
<li>Both certificates uploaded to Azure through the portal</li>
<li>A <code>&lt;appSecrets&gt;</code> section in your config for local secrets that is encrypted</li>
</ol>


<p>Phew! With all this in place, here&rsquo;s what this gets you:</p>

<ol>
<li>Encryption keys are not known, therefore the <strong>most</strong> an attacker could do if they compromised the application is to decrypt every user through Key Vault which is an audited system and slows them down</li>
<li>Your production secrets are not stored anywhere in your application or source control, local secrets and connection strings are encrypted</li>
<li>No cleartext tokens are used to access Key Vault, instead a signed certificate is used</li>
</ol>


<h2>Implementation notes</h2>

<p>The article above for getting started with a web app is a good place to start but I did a few things to make it easy to test and work with locally.</p>

<ol>
<li>I created an <code>ISecretsProvider</code> interface with two implementations: a config provider (see above) and a Key Vault provider. This also lets me mock for testability.</li>
<li>When I bind the <code>ISecretsProvider</code> for dependency injection, I inspect the current environment and use the appropriate provider (config locally, key vault otherwise)</li>
</ol>


<p>```csharp
// Ninject example</p>

<p>// Secrets provider
kernel.Bind<ISecretsProvider>().ToMethod(ctx =>
{</p>

<pre><code>switch (AppSettings.RuntimeEnvironment)
{
    case RuntimeEnvironment.D:
    case RuntimeEnvironment.P:
        return new AzureKeyVaultSecretsProvider();
    default:
        return new ConfigSecretsProvider();
}
</code></pre>

<p>}).InSingletonScope();
```</p>

<p>Some other thoughts of what you might want to do:</p>

<ul>
<li>Add some logging/telemetry around calls to key vault, such as <a href="https://azure.microsoft.com/en-us/documentation/articles/app-insights-api-custom-events-metrics/#track-dependency">App Insights' track dependency</a></li>
<li>When the Key Vault client supports returning <code>SecureStrings</code>, you could use that to protect secrets in memory</li>
<li>Rotate encryption keys every so often (store the version of the key used on the entities), though this might be pricey for HSM keys</li>
<li>Encrypt secrets before storing them and then decrypt them at runtime (might be overkill)</li>
</ul>


<h3>A word on storing secrets in-memory</h3>

<p>Ideally you would only access secrets as-needed and not store them in memory. But there are some things to consider:</p>

<ul>
<li>If an attacker has compromised your process memory somehow, they&rsquo;ve owned you anyway.</li>
<li>While $0.13/10,000 operations seems cheap, it would add up if you had to call Key Vault <strong>every</strong> time you needed to use a secret</li>
<li>Calling Azure Key Vault does incur some latency, even if it&rsquo;s minimal&mdash;remember that their SLA is 99.9% within 5 seconds so it&rsquo;s possible latency could be pretty poor</li>
<li>At least with the <em>current</em> KeyVault client, it does <strong>not</strong> return secrets as <code>SecureStrings</code>, so it will be in cleartext in memory <em>anyway</em> so what&rsquo;s the difference? (Maybe <a href="https://github.com/Azure/azure-sdk-for-net/issues/1819">they will fix that</a>.)</li>
</ul>


<p>It&rsquo;s up to you but those are my thoughts.</p>

<h2>Troubleshooting</h2>

<p>I ran into a bunch of problems during the writing of this guide. Hopefully these help:</p>

<h3>When I run my app and try to get a secret from Key Vault I get a &ldquo;Keyset does not exist&rdquo; error</h3>

<p>Your app pool/user running the app does not have access to the private key. Follow my advice above to change the app pool identity to your own user account.</p>

<p>I use an app setting to determine where my app is running.</p>

<h3>When I run my app, I get a &ldquo;Bad Key&rdquo; error from the config encryption provider</h3>

<p>You are trying to use the same cert you made for Azure AD, you can&rsquo;t do this. Follow the guide I linked to above to make a new <code>azureconfig</code> cert and import it the same way you did before (to both certificate stores).</p>

<h3>When I build my app in Azure through Continuous Deployment, it&rsquo;s not able to decrypt the web.config</h3>

<ol>
<li>Ensure you uploaded the config PFX file through the portal</li>
<li>Ensure you restarted the application (or Stop then Start)</li>
<li>You can use the Kudu console to run Powershell to check if your cert is uploaded.</li>
<li><code>PS&gt; Set-Location Cert:\CurrentUser\My</code></li>
<li><code>PS&gt; Get-ChildItem</code></li>
<li>Ensure the <code>storeLocation</code> attribute in the web.config is set to <code>CurrentUser</code></li>
<li>Ensure you <strong>are not</strong> encrypting the <code>&lt;appSettings&gt;</code> config section, it&rsquo;s not supported (use the <code>appSecrets</code> workaround above)</li>
<li>Ensure your <code>thumbprint</code> matches the certificate thumbprint</li>
</ol>

]]></content>
  </entry>
  
</feed>
