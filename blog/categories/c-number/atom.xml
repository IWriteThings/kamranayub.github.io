<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: C# | Kamranicus]]></title>
  <link href="http://kamranicus.com/blog/categories/c-number/atom.xml" rel="self"/>
  <link href="http://kamranicus.com/"/>
  <updated>2016-03-06T16:13:10+00:00</updated>
  <id>http://kamranicus.com/</id>
  <author>
    <name><![CDATA[Kamran]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Handling Multiple Origins in CORS Using URL Rewrite]]></title>
    <link href="http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis/"/>
    <updated>2016-03-06T15:50:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis</id>
    <content type="html"><![CDATA[<p>Here&rsquo;s a quick tip if you&rsquo;re trying to figure out how to handle <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">cross-origin requests (CORS)</a> when you have multiple origins (namely, HTTP and HTTPS). This works in IIS 8.0 and above, including Azure, as long as you have the <a href="http://www.iis.net/downloads/microsoft/url-rewrite">URL Rewrite module</a> installed.</p>

<p>The CORS header looks like this:</p>

<p><code>
Access-Control-Allow-Origin: http://mydomain.com
</code></p>

<p>The spec is very strict. The header can only return a single value and it must be absolutely qualified, which means if you have a site that is served over HTTP and HTTPS (or multiple domains), you need to <em>dynamically</em> build this header in your response. Many tutorials and blog posts say to specify <code>*</code> as the value&mdash;<strong>DO NOT DO THIS!</strong> This means any origin (domain) can embed/request assets from your website. Unless you have hundreds of sites doing this (aka CDN), you should only whitelist the domains that can include resources from your site.</p>

<p>If you are sharing resources with a known number of hosts, the following method will help. If it&rsquo;s a <em>dynamic</em> list, you will need to programmatically add the <code>Access-Control-Allow-Origin</code> header depending on the incoming <code>Origin</code> header&mdash;something I won&rsquo;t cover here.</p>

<p>Rather than messing with C# and modifying outgoing responses what I ended up using was a simple URL rewrite rule, proposed by <a href="http://stackoverflow.com/a/31084390/109458">this Stack Overflow answer</a>. All it does is add a header to the outbound response when the regular expression matches&mdash;in this case, whitelisting only the HTTP and HTTPS version of my domain (or subdomain).</p>

<p>```
&lt;system.webServer>
   <httpProtocol></p>

<pre><code> &lt;customHeaders&gt;
     &lt;add name="Access-Control-Allow-Headers" value="Origin, X-Requested-With, Content-Type, Accept" /&gt;
     &lt;add name="Access-Control-Allow-Methods" value="POST,GET,OPTIONS,PUT,DELETE" /&gt;
 &lt;/customHeaders&gt;
</code></pre>

<p>   </httpProtocol></p>

<pre><code>    &lt;rewrite&gt;            
        &lt;outboundRules&gt;
            &lt;clear /&gt;                
            &lt;rule name="AddCrossDomainHeader"&gt;
                &lt;match serverVariable="RESPONSE_Access_Control_Allow_Origin" pattern=".*" /&gt;
                &lt;conditions logicalGrouping="MatchAll" trackAllCaptures="true"&gt;
                    &lt;add input="{HTTP_ORIGIN}" pattern="(http(s)?:\/\/((.+\.)?mydomain\.com))" /&gt;
                &lt;/conditions&gt;
                &lt;action type="Rewrite" value="{C:0}" /&gt;
            &lt;/rule&gt;           
        &lt;/outboundRules&gt;
    &lt;/rewrite&gt;
</code></pre>

<p> &lt;/system.webServer>
 ```</p>

<p>This is using special syntax of the URL Rewrite module (<code>RESPONSE_</code>) to add a outgoing response header (dashes replaced with underscores). Then it matches the <em>incoming</em> <code>Origin</code> header, compares the value, and if it matches includes the CORS header with the value of my domain.</p>

<p> That was all I had to do!</p>

<p> <strong>Note:</strong> Since I just converted over to always SSL, I no longer need this workaround but multiple origins is pretty common when dealing with CORS so this solution will come in handy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Securing Secrets Using Azure Key Vault and Config Encryption]]></title>
    <link href="http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure/"/>
    <updated>2016-02-24T02:30:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure</id>
    <content type="html"><![CDATA[<p>Secrets. We all have them. I&rsquo;m talking about secrets like your database connection strings, API keys and encryption keys. Where are you storing yours? Are you storing them&hellip;</p>

<ol>
<li>In your application&rsquo;s source code?</li>
<li>In a config file (<code>appSettings</code> or otherwise) checked into source control?</li>
<li>In a database?</li>
<li>In a managed portal, like Azure?</li>
</ol>


<p>I hope you aren&rsquo;t storing them hardcoded. You&rsquo;re probably doing option 2 or a hybrid of options 2-4. Even if you use an external data source, it&rsquo;s hard to escape the need for secrets in local development unless you force your app to rely on having connectivity which makes it hard to work offline.</p>

<p>In this post I&rsquo;m going to provide some suggestions on how to store your secrets better using Azure Key Vault and config file encryption, specifically in the context of Azure but the concepts apply to any hosting environment.</p>

<!-- More -->


<h2>Why bother?</h2>

<p>Some of you might say, &ldquo;It&rsquo;s okay if my secret is in a config file or an environment variable, only an admin can see that.&rdquo; You&rsquo;d assume so, wouldn&rsquo;t you? But I ran into an exploit last year where you could view <strong>ANY</strong> file on the web server using a custom file handler vulnerability (the exploit has since been fixed by the vendor). Just pass in the path you cared about and the handler would helpfully spit out the contents of the file! If your secrets are in cleartext in your configs, are you checking them into source control? Anyone can read those if they have access. If you work in an organization and your code is on the web servers, anyone with access to those servers can see the file system (and therefore, your precious &ldquo;secrets&rdquo;).</p>

<p>You might also (rightfully) say that if an attacker got access to your Azure portal, it&rsquo;s game over anyway. Yes, absolutely. If an app is compromised at the filesystem level where an attacker can upload files, you&rsquo;re pretty much done for. That&rsquo;s why your portal account should have a strong password and have Two-Factor Authentication enabled. If you&rsquo;re using source control integration, that also needs to be protected with the same amount of security to prevent someone from checking in malicious files and having them deployed through automation to the web server&mdash;go and <a href="https://help.github.com/articles/about-two-factor-authentication/">enable TFA for GitHub</a> if you haven&rsquo;t already.  The goal is that we want to avoid storing plaintext secrets on the filesystem and in the portal itself, instead opting to store them in a secure location so that only <strong>our application</strong> has access to them, no one else.</p>

<p>There are more benefits to separating your secrets from your application:</p>

<ul>
<li><strong>Logging</strong> &mdash; Azure Key Vault logs all operations, so if someone did compromise your application, you&rsquo;d have the logs or could monitor them closely for strange actions</li>
<li><strong>Least privilege</strong> &mdash; You can grant a service principal Read-only access so even if the app was compromised, an attacker couldn&rsquo;t change or delete anything (unless they also had access to change the policies in Key Vault)</li>
<li><strong>As-needed access</strong> &mdash; By storing secrets away from your application, you at <em>least</em> guarantee only the application can access secrets whereas anyone with Read access to the portal can see app settings</li>
<li><strong>Defense in depth</strong> &mdash; You&rsquo;re just adding one more layer of security between an attacker and your data</li>
<li><strong>Shared storage</strong> &mdash; If you have multiple apps or services, using a single vault is useful and you can grant access policies at the secret or key level</li>
<li><strong>Encrypted configs</strong> &mdash; Instead of storing secrets in cleartext in source control, I will show you how to encrypt sections of your web.config (and it works in Azure!)</li>
<li><strong>Right thing to do</strong> &mdash; You owe it to your users and to your business to protect their data to the best of your ability</li>
</ul>


<p><a href="http://blogs.msdn.com/b/data_insights_global_practice/archive/2015/09/24/protecting-sensitive-data-with-azure-key-vault.aspx">This article</a> sums it up nicely:</p>

<blockquote><p>One of the key security principals that is implicitly being applied here is to compartmentalize management of privileged data to security domains for which this is appropriate. An instance of Key Vault is used to manage the Twitter keys as a shared resource in the customer&rsquo;s environment, with access granted by whomever manages the Twitter account on an as-needed basis to specific applications and users. Applications are then responsible for managing only their application-specific Key Vault access tokens.</p></blockquote>

<p>With that in mind, let&rsquo;s move on!</p>

<h2>Encryption keys</h2>

<p>The most important secret in your app is probably your <strong>encryption key</strong> (aka &ldquo;keys&rdquo;). This is the skeleton key to your kingdom. If someone got ahold of it, they could unlock your user&rsquo;s data and tarnish your reputation. If your Azure or portal account was compromised (even after Two Factor Auth), would attackers have access to your keys? They would if you stored them in a config or in the portal. So how can you protect this key if none of the options above truly secure it?</p>

<p>Well, what if I told you that <strong>you don&rsquo;t need to know the key</strong>. If nobody knows it, no one can steal it! But how does that work exactly? Magic? Not exactly&hellip;</p>

<h2>Welcome to the vault</h2>

<p>Enter <a href="https://azure.microsoft.com/en-us/services/key-vault/">Azure Key Vault</a>.</p>

<p>Azure Key Vault does two things:</p>

<ul>
<li>It stores encryption &ldquo;keys&rdquo; which <strong>you cannot retrieve</strong> so that you can encrypt and decrypt data, you&rsquo;d use this for user data like PII (Personally Identifiable Information)</li>
<li>It stores &ldquo;secrets&rdquo; which <strong>you can</strong> retrieve, these are things like passwords, API tokens, or other items you pass around</li>
</ul>


<p>A word about how Azure Key Vault stores keys. It&rsquo;s basically the most hardcore thing ever. If you opt for the Premium service tier, your key is stored on <strong>dedicated hardware</strong> called a Hardware Security Module (HSM). I had never heard of these so let me clue you in: they are <strong><a href="https://en.wikipedia.org/wiki/Hardware_security_module">devices</a></strong> where all they do is encrypt and decrypt data and never let the key leave their boundaries. That means, essentially, you present the data you want to encrypt to the device, it encrypts it using a key that <strong>nobody knows</strong>, and spits out the ciphertext for you to store in your system. Azure Key Vault also supports <em>software-protected</em> keys which can operate under the same conditions except they are not stored on a dedicated device. The HSM is validated to be <a href="https://en.wikipedia.org/wiki/FIPS_140-2#Level_2">FIPS 140-2 Level 2</a> compliant (out of 4 levels). What does that mean exactly?</p>

<p>Well, here&rsquo;s Level 1 security:</p>

<blockquote><p>Level 1 provides the lowest level of security. Basic security requirements are specified for a cryptographic module (e.g., at least one Approved algorithm or Approved security function shall be used). No specific physical security mechanisms are required in a Security Level 1 cryptographic module beyond the basic requirement for production-grade components. An example of a Security Level 1 cryptographic module is a personal computer (PC) encryption board.</p></blockquote>

<p>OK, so we&rsquo;re still talking <strong>a dedicated encryption board</strong> to secure keys&hellip; how about Level 2?</p>

<blockquote><p>Security Level 2 improves upon the physical security mechanisms of a Security Level 1 cryptographic module by requiring features that show evidence of tampering, including tamper-evident coatings or seals that must be broken to attain physical access to the plaintext cryptographic keys and critical security parameters (CSPs) within the module, or pick-resistant locks on covers or doors to protect against unauthorized physical access.</p></blockquote>

<p>Jeez. That means there are <em>physical defenses</em> in place on the device to prevent intrusion. We&rsquo;re not even talking intrusion through the network, no, literally these devices are secured so a <strong>human being</strong> cannot access them. Even if it&rsquo;s not Level 4, that&rsquo;s still <em>way</em> more secure than in your App.config or your database or web portal. And even Wikipedia admits that &ldquo;<a href="https://en.wikipedia.org/wiki/Hardware_security_module#Security">very few</a>&rdquo; HSMs are Level 4 validated.</p>

<p>You&rsquo;d think this hardcore security would be pricey right? Not at all. I think the <a href="https://azure.microsoft.com/en-us/pricing/details/key-vault/">$1/key/mo</a> price tag is pretty fair considering the security offered.</p>

<h2>What about secrets?</h2>

<p>OK. So Azure Key Vault is a pretty good solution to our encryption key problem. What about generic secrets, stuff you will need to pass within your application or to external services? Azure Key Vault supports that without any trouble, though they won&rsquo;t be stored on dedicated hardware. They will still be stored separately from your application behind lock and key which is our ultimate goal.</p>

<h2>But even a safe needs a combination, won&rsquo;t the <em>vault</em> require a key?</h2>

<p>Yes! And you are right to point out that it doesn&rsquo;t really solve the secrets problem if the key I need to use to unlock the vault is <em>also</em> stored in my app.config or portal or database. Luckily, there&rsquo;s a way to solve that!</p>

<h2>Certificates to the rescue</h2>

<p>Instead of using the default authentication to Azure AD, a &ldquo;client ID&rdquo; and &ldquo;secret token&rdquo;, we will actually provide a secure X.509 certificate that we&rsquo;ll upload to Azure. Since you can&rsquo;t download the certificate from Azure or access the private key, it will authenticate your application without exposing the key to your vault in a config or portal interface.</p>

<h2>Let&rsquo;s do it!</h2>

<p>I followed these two guides for setting up Key Vault and authenticating using a certificate, so I won&rsquo;t repeat the steps here but I do have several notes below that augment the guides:</p>

<ol>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-get-started/">Getting Started with Azure Key Vault</a></li>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-use-from-web-application">Using Azure Key Vault from a Web Application</a></li>
</ol>


<p>Follow the appendix in guide 2 to generate a certificate to authenticate to Azure AD.</p>

<p>As you work through the guides, reference the notes below.</p>

<h3>PowerShell Cmdlet Changes</h3>

<p>For guide 2, in Azure SDK 2.8+, the cmdlets have changed now:</p>

<ul>
<li><code>New-AzureADApplication</code> is now <code>New-AzureRmADApplication</code></li>
<li><code>New-AzureADServicePrincipal</code> is now <code>New-AzureRmADServicePrincipal</code></li>
</ul>


<p>When executing <code>Set-AzureKeyVaultAccessPolicy</code> make sure to add the switch <code>-PermissionsToSecrets all</code> to grant permissions to manage secrets.</p>

<p><strong>Note:</strong> The article tells you to grant <code>all</code> permissions to both keys and secrets. In reality, for production, you may want to only grant specific rights. See <a href="https://msdn.microsoft.com/en-us/library/dn903607.aspx">this MSDN article</a> for the different access policies.</p>

<h3>Certificates&hellip;?</h3>

<p>If you&rsquo;re like me, you probably find certificates can be confusing. Are you making an SSL cert? Not exactly. <em>Most</em> SSL certs are X.509 certs (not all) but they also can be used to encrypt web traffic. &ldquo;Plain&rdquo; X.509 certs can be used to sign things or encrypt/authenticate, which is what we&rsquo;re doing. If you Google around, you&rsquo;ll see they can be called &ldquo;client certificates&rdquo; or &ldquo;personal&rdquo; certificates. There are two places a cert can be installed (&ldquo;stores&rdquo;), one is the &ldquo;Local Machine&rdquo; store and the other is the &ldquo;Current User&rdquo; store. The machine store can be accessed by <em>any</em> user account, the current user store can only be accessed by the user running the process (usually, you). A &ldquo;cer&rdquo; file is the <strong>public key</strong> for your certificate. You can distribute it to anyone. The &ldquo;pfx&rdquo; file contains <strong>both the private AND public key</strong>. <strong>DO NOT GIVE IT TO ANYONE.</strong> You want the PFX file for yourself only and to import into your PC and into Azure. The PFX file is protected by a password, I recommend a strong one and <em>don&rsquo;t lose it.</em> Rule of thumb: <strong>NEVER let the private key leave your machine. This means don&rsquo;t email it. Yes, this has really happened before.</strong></p>

<h3>Certificate key length</h3>

<p>In guide 2, you create a self-signed certificate. For production should you use a commercially-signed cert? I can&rsquo;t think of a reason why that would add any extra benefit since the <strong>key length</strong> is what matters (if you <em>can</em> think of a reason, I&rsquo;d be interested in hearing it). What I <em>would</em> recommend is generating a certificate with a 4096-bit length key instead of the default 2048 length. In Windows 10 at least, this works:</p>

<p><code>
makecert -sv mykey.pvk -n "cn=KVWebApp" KVWebApp.cer -b 02/23/2016 -e 02/23/2018 -len 4096 -r
</code></p>

<p>If you live in fear, you can buy &ldquo;personal&rdquo; certs from trusted authorities like <a href="https://ssl.comodo.com/personal-authentication.php">Comodo</a> and use that instead.</p>

<h3>Install the certificate</h3>

<p>For guide 2, after generating the certificate you need to install it locally to test Azure Key Vault. If you run your app under IIS and the app pool is <code>ApplicationPoolIdentity</code>, it&rsquo;s best to just <a href="http://www.iis.net/learn/manage/configuring-security/application-pool-identities">change it</a> to run under your account. Trust me, it&rsquo;ll be easier. Since Azure requires the certificate to be in the <code>CurrentUser</code> store, the default app pool runs under a different account (see <a href="http://stackoverflow.com/a/3176253/109458">this StackOverflow post</a>), so you&rsquo;d have to install the cert at the machine level.</p>

<p>In the folder where your cert was generated, right-click the <code>.pfx</code> file and select Install. Enter the password you chose. You can also <a href="http://www.databasemart.com/howto/SQLoverssl/How_To_Import_Personal_Certificate_With_MMC.aspx">follow this guide</a> to do it from the MMC console.</p>

<h2>Alright, so what about local secrets?</h2>

<p>We have the cloud secrets squared away. You <em>could</em> still use Key Vault locally, except you&rsquo;d depend on connectivity (and pay for the usage). Instead, there&rsquo;s something we can do even if we don&rsquo;t end up using Azure Key Vault. We can <strong>encrypt the settings</strong> in the web.config.</p>

<p>I started with <a href="http://eren.ws/2014/02/04/encrypting-the-web-config-file-of-an-azure-cloud-service">this guide</a> to encrypting the configuration sections (but <strong>NOT</strong> <code>appSettings</code>, see below). You <strong>cannot</strong> use the same certificate you generated in the tutorial above (well, maybe you could but you need the <code>-exchange sky</code> switch to <code>makecert</code> and I didn&rsquo;t try that initially so I generated a separate certificate).</p>

<p>There&rsquo;s another thing. You also need to use a different <code>PKCS12ProtectedConfigurationProvider</code>. The one provided <strong>only</strong> searches the <code>LocalMachine</code> certificate store but in Azure, your cert is installed for the current user, so the provider fails to decrypt the config when you try to build your app on Azure because it cannot find the certificate. You need a provider that can specify the <code>StoreLocation</code> of where to load certificates from. For Azure, it must be the <strong>CurrentUser</strong> store.</p>

<p>Here&rsquo;s my modified version:</p>

<script src="https://gist.github.com/kamranayub/eaf4c4e4983ecb2d0b37.js"></script>


<p>I&rsquo;ve also added it to <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider">GitHub</a>. You can download the DLL directly from <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider/releases/tag/v1.0.1">GitHub</a>. Once done, you can change the entry in the config to:</p>

<p>```</p>

<pre><code>&lt;configProtectedData&gt;
    &lt;providers&gt;
        &lt;add name="CustomProvider"
             thumbprint="xxx"
             storeLocation="LocalMachine"
             type="Pkcs12ProtectedConfigurationProvider.Pkcs12ProtectedConfigurationProvider, PKCS12ProtectedConfigurationProvider, Version=1.0.1.0, Culture=neutral, PublicKeyToken=455a6e7bdbdc9023" /&gt;
    &lt;/providers&gt;
&lt;/configProtectedData&gt;
</code></pre>

<p>```</p>

<p>A few notes:</p>

<ol>
<li>This <strong>is not</strong> the same certificate you generated for Azure AD and Key Vault. This is a separate RSA certificate for use with configuration encryption. You must <em>also</em> upload the PFX for this to Azure.</li>
<li>You will need to install the PKCS12ProtectedConfigurationProvider.dll to the GAC before running the <code>aspnet_regiis</code> command. Just run <code>gacutil -i PKCS12ProtectedConfigurationProvider.dll</code> beforehand.</li>
<li>You will need to reference the custom compiled DLL instead of the one in the guide</li>
<li>I found <a href="http://stackoverflow.com/questions/17189441/web-config-encryption-for-web-sites">this StackOverflow question</a> which asks about encrypting the web.config for Azure web apps. Using the PKCS12 provider, <strong>it works.</strong></li>
</ol>


<h3>Storing secrets outside <code>&lt;appSettings&gt;</code></h3>

<p>I ran into a major hurdle that caused me some grief. It turns out, <strong>YOU CANNOT ENCRYPT THE <code>&lt;appSettings&gt;</code> SECTION!</strong> See <a href="http://stackoverflow.com/questions/15067759/why-cant-i-encrypt-web-config-appsettings-using-a-custom-configprotectionprovid">this SO question</a>.</p>

<p>Other sections are just fine but for whatever reason, IIS just <strong>requires</strong> you to GAC the config provider for it to work. In Azure web apps, we cannot GAC. So what can we do? We can use our <strong>own</strong> config section!</p>

<p>Here&rsquo;s an implementation example of an <code>ISecretsProvider</code> contract and a <code>ConfigSecretsProvider</code> example implementation. You&rsquo;d also create an <code>AzureKeyVaultSecretsProvider</code> probably to handle getting secrets from Azure Key Vault using the code from the guides above.</p>

<script src="https://gist.github.com/kamranayub/eb6518356ac2b2f1a72a.js"></script>


<p>The <code>ConfigSecretsProvider</code> will use environment variables defined in Azure <em>first</em> then fallback to the config. This mirrors how app settings work in Azure.</p>

<p><strong>Note:</strong> Here I am deciding to use only one provider per environment. You might want an implementation that actually uses both. My Key Vault implementation actually uses the <code>ConfigSecretsProvider</code> to find the URL to load the secret for, so that in Azure, the app settings just specify the Key Vault secret URL to load:</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/13271735/9a0f600a-da5c-11e5-9ff0-106d5e009464.png" alt="App settings in Azure" /></p>

<p>This way, locally I can use the raw value (encrypted) and then in Azure, reference the URL for the secret.</p>

<p>To encrypt the <code>&lt;appSecrets&gt;</code> section, just run the the command (in the same directory as the web.config and using the Visual Studio Command Prompt):</p>

<p><code>
aspnet_regiis -pef appSecrets . -prov CustomProvider
</code></p>

<p>And to decrypt:</p>

<p><code>
aspnet_regiis -pdf appSecrets .
</code></p>

<p>Easy peasy!</p>

<h2>So where are we at?</h2>

<p>If you followed all the guides I linked to and followed the notes, you should have the following:</p>

<ol>
<li>An Azure Key Vault set up with a secret to test with</li>
<li>A certificate that authenticates against Azure AD</li>
<li>A certificate that can encrypt/decrypt your web.config</li>
<li>Both certificates uploaded to Azure through the portal</li>
<li>A <code>&lt;appSecrets&gt;</code> section in your config for local secrets that is encrypted</li>
</ol>


<p>Phew! With all this in place, here&rsquo;s what this gets you:</p>

<ol>
<li>Encryption keys are not known, therefore the <strong>most</strong> an attacker could do if they compromised the application is to decrypt every user through Key Vault which is an audited system and slows them down</li>
<li>Your production secrets are not stored anywhere in your application or source control, local secrets and connection strings are encrypted</li>
<li>No cleartext tokens are used to access Key Vault, instead a signed certificate is used</li>
</ol>


<h2>Implementation notes</h2>

<p>The article above for getting started with a web app is a good place to start but I did a few things to make it easy to test and work with locally.</p>

<ol>
<li>I created an <code>ISecretsProvider</code> interface with two implementations: a config provider (see above) and a Key Vault provider. This also lets me mock for testability.</li>
<li>When I bind the <code>ISecretsProvider</code> for dependency injection, I inspect the current environment and use the appropriate provider (config locally, key vault otherwise)</li>
</ol>


<p>```csharp
// Ninject example</p>

<p>// Secrets provider
kernel.Bind<ISecretsProvider>().ToMethod(ctx =>
{</p>

<pre><code>switch (AppSettings.RuntimeEnvironment)
{
    case RuntimeEnvironment.D:
    case RuntimeEnvironment.P:
        return new AzureKeyVaultSecretsProvider();
    default:
        return new ConfigSecretsProvider();
}
</code></pre>

<p>}).InSingletonScope();
```</p>

<p>Some other thoughts of what you might want to do:</p>

<ul>
<li>Add some logging/telemetry around calls to key vault, such as <a href="https://azure.microsoft.com/en-us/documentation/articles/app-insights-api-custom-events-metrics/#track-dependency">App Insights' track dependency</a></li>
<li>When the Key Vault client supports returning <code>SecureStrings</code>, you could use that to protect secrets in memory</li>
<li>Rotate encryption keys every so often (store the version of the key used on the entities), though this might be pricey for HSM keys</li>
<li>Encrypt secrets before storing them and then decrypt them at runtime (might be overkill)</li>
</ul>


<h3>A word on storing secrets in-memory</h3>

<p>Ideally you would only access secrets as-needed and not store them in memory. But there are some things to consider:</p>

<ul>
<li>If an attacker has compromised your process memory somehow, they&rsquo;ve owned you anyway.</li>
<li>While $0.13/10,000 operations seems cheap, it would add up if you had to call Key Vault <strong>every</strong> time you needed to use a secret</li>
<li>Calling Azure Key Vault does incur some latency, even if it&rsquo;s minimal&mdash;remember that their SLA is 99.9% within 5 seconds so it&rsquo;s possible latency could be pretty poor</li>
<li>At least with the <em>current</em> KeyVault client, it does <strong>not</strong> return secrets as <code>SecureStrings</code>, so it will be in cleartext in memory <em>anyway</em> so what&rsquo;s the difference? (Maybe <a href="https://github.com/Azure/azure-sdk-for-net/issues/1819">they will fix that</a>.)</li>
</ul>


<p>It&rsquo;s up to you but those are my thoughts.</p>

<h2>Troubleshooting</h2>

<p>I ran into a bunch of problems during the writing of this guide. Hopefully these help:</p>

<h3>When I run my app and try to get a secret from Key Vault I get a &ldquo;Keyset does not exist&rdquo; error</h3>

<p>Your app pool/user running the app does not have access to the private key. Follow my advice above to change the app pool identity to your own user account.</p>

<p>I use an app setting to determine where my app is running.</p>

<h3>When I run my app, I get a &ldquo;Bad Key&rdquo; error from the config encryption provider</h3>

<p>You are trying to use the same cert you made for Azure AD, you can&rsquo;t do this. Follow the guide I linked to above to make a new <code>azureconfig</code> cert and import it the same way you did before (to both certificate stores).</p>

<h3>When I build my app in Azure through Continuous Deployment, it&rsquo;s not able to decrypt the web.config</h3>

<ol>
<li>Ensure you uploaded the config PFX file through the portal</li>
<li>Ensure you restarted the application (or Stop then Start)</li>
<li>You can use the Kudu console to run Powershell to check if your cert is uploaded.</li>
<li><code>PS&gt; Set-Location Cert:\CurrentUser\My</code></li>
<li><code>PS&gt; Get-ChildItem</code></li>
<li>Ensure the <code>storeLocation</code> attribute in the web.config is set to <code>CurrentUser</code></li>
<li>Ensure you <strong>are not</strong> encrypting the <code>&lt;appSettings&gt;</code> config section, it&rsquo;s not supported (use the <code>appSecrets</code> workaround above)</li>
<li>Ensure your <code>thumbprint</code> matches the certificate thumbprint</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tools of the Trade 2016]]></title>
    <link href="http://kamranicus.com/blog/2016/02/09/tools-of-the-trade/"/>
    <updated>2016-02-09T03:09:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/02/09/tools-of-the-trade</id>
    <content type="html"><![CDATA[<p>Sometimes you get so caught up in the work you do on a daily basis that you forget what it was like to start your job on day one&mdash;not knowing anything about what tools, extensions, and general utilities you take for granted now, 6 years into your career. It seems like on a monthly basis I find a new extension or utility that is useful to me. I wanted to share my toolbelt, in case it contains something you&rsquo;ve never heard of and causes you to exclaim in excitement about something awesome that you&rsquo;ll start using today.</p>

<!-- More -->


<p>This list is organized by function&mdash;i.e. what the tool contributes to for my work. If I use extensions for a tool, I will list them under the tool. I&rsquo;ve definitely used more things than I list here but I use these on a day-by-day basis typically and are what I would consider essential to my workflow. Share any awesome tools you use that I missed in the comments! If I think of more, I&rsquo;ll add them below.</p>

<h2>Coding</h2>

<p>I work with JavaScript/TypeScript, HTML, CSS, and C# on a daily basis. Here&rsquo;s what I use and for what.</p>

<h3><a href="https://go.microsoft.com/fwlink/?LinkId=691978&amp;clcid=0x409">Visual Studio 2015 Pro/Community</a></h3>

<p>For primary .NET work, web app work, and work-work. I use Community edition at home, it&rsquo;s free!</p>

<p><strong>Extensions</strong></p>

<ul>
<li><a href="https://www.jetbrains.com/resharper/download/">ReSharper 10</a> &ndash; Oodles of time-saving refactoring helpers and code analysis</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/3b329021-cd7a-4a01-86fc-714c2d05bb6c">Web Compiler</a> &ndash; for LESS, SASS compiling</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/e1d68248-f30e-4a5d-bf18-31399a0bcfa6">Typewriter</a> (see my recent <a href="http://kamranicus.com/blog/2016/02/04/typewriter/">blog post</a>) &ndash; for T4-style TypeScript codegen</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/ee6e6d8c-c837-41fb-886a-6b50ae2d06a2">Web Essentials 2015</a> &ndash; for web dev</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/1f6ec6ff-e89b-4c47-8e79-d2d68df894ec">Razor Generator</a> &ndash; for Razor templates for emails</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/dd1dc8a5-d627-48a2-a19d-df4fe0c47f19">Node.js Tools for Visual Studio</a> &ndash; for Node.js projects</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/c9eb3ba8-0c59-4944-9a62-6eee37294597">PowerShell Tools for Visual Studio</a> &ndash; for interactive PowerShell prompt and editing</li>
<li><a href="https://visualstudiogallery.msdn.microsoft.com/410e9b9f-65f3-4495-b68e-15567e543c58">Rebracer</a> &ndash; save formatting settings per solution</li>
</ul>


<h3><a href="http://code.visualstudio.com">Visual Studio Code</a></h3>

<p>For working on lots of my JS/TS-based OSS projects like <a href="http://excaliburjs.com">Excalibur.js</a>. The cross-platform, Git-integrated nature of the IDE is awesome along with per-project user settings to keep everyone in-sync.</p>

<p><strong>Extensions</strong></p>

<ul>
<li>ReStructured Text &ndash; for <a href="http://docs.excaliburjs.com">Excalibur docs</a></li>
<li>PowerShell &ndash; for scripts</li>
</ul>


<h3><a href="https://www.sublimetext.com">Sublime Text 3</a></h3>

<p>I use Sublime for note-taking (auto-save) and quick file editing since it&rsquo;s so fast and has a context-menu shortcut to edit files.</p>

<h3><a href="http://github.com">GitHub</a></h3>

<p>I pay for a plan at GitHub for private source code hosting but I also use it for all my <a href="http://github.com/kamranayub">OSS development</a>. It&rsquo;s a staple of my coding workflow.</p>

<h3><a href="http://desktop.github.com">GitHub Desktop</a></h3>

<p>For working with GitHub projects and local Git repositories, I also like that launches posh-git for the shell.</p>

<h3><a href="http://linqpad.com">Linqpad 5</a></h3>

<p>For quick C# script testing, database queries, etc.</p>

<h3><a href="https://technet.microsoft.com/en-us/scriptcenter/dd742419.aspx">PowerShell &amp; ISE</a></h3>

<p>I recently <a href="http://kamranicus.com/blog/2015/09/17/powershell-html5-offline-manifest/">became a believer</a> in PowerShell, for automation and scripting it&rsquo;s awesome. Just <a href="https://mva.microsoft.com/en-US/training-courses/getting-started-with-powershell-3-0-jump-start-8276">take the few hours</a> and learn it, you won&rsquo;t regret it. ISE is the scripting editor built into Windows.</p>

<h3><a href="https://github.com/dahlbyk/posh-git">posh-git</a></h3>

<p>The default shell for GH Desktop (above), posh-git is a PowerShell prompt with Git integration.</p>

<h2>Multimedia</h2>

<h3><a href="http://www.adobe.com/creativecloud.html">Adobe Creative Cloud</a></h3>

<p>The subscription-based model softens the blow of owning Adobe products and, perhaps, costs more over time but the benefits outweigh the negatives&mdash;namely, I own the full suite of Adobe products (<em>cough</em> legally) and they&rsquo;re <strong>always</strong> up-to-date with new versions so I don&rsquo;t need to pay up-the-nose every year. I also really like TypeKit for syncing new fonts.</p>

<h3><a href="http://www.aseprite.org/">aseprite Editor</a></h3>

<p>This is for pixel graphics and sprites, ASE is great for pixel-perfect drawings and animations.</p>

<h3><a href="http://www.mapeditor.org/">Tiled Map Editor</a></h3>

<p>For creating game maps using the spritesheets and tilesets I made from ASE/Photoshop (or purchased). Tiled also exports to JSON, making it easy to <a href="http://github.com/excaliburjs/excalibur-tiled">integrate with game engines</a>.</p>

<h3><a href="http://www.audacityteam.org/">Audacity</a></h3>

<p>I use Audacity for audio editing since it&rsquo;s easy to use and very lightweight.</p>

<h3><a href="http://www.virtualdub.org/">VirtualDub</a></h3>

<p>Simple video editor and great for transencoding video formats.</p>

<h3><a href="https://obsproject.com/download#mp">Open Broadcasting Studio</a></h3>

<p>For streaming and screen recording, you can&rsquo;t beat the FOSS OBS Studio. The new version is hot stuff and is a total rewrite of the &ldquo;Classic&rdquo; version.</p>

<h2>Productivity</h2>

<h3><a href="http://www.teamviewer.com/en-us/">TeamViewer</a></h3>

<p>I use TeamViewer because it&rsquo;s dead simple to set up and manage remote access to my machines without fiddling with firewalls or port forwarding. They also have native mobile clients for on-the-go RDP.</p>

<h3><a href="https://products.office.com/en-us/office-365-home">OneNote / Office 365</a></h3>

<p>I use OneNote for password-protected information (it&rsquo;s actually encrypted) and for cross-device note syncing. O365 is great for the cross-platform Office and syncing via OneDrive.</p>

<h3><a href="http://onedrive.com">OneDrive</a></h3>

<p>I use OneDrive for its cross-platform syncing (PC/Android/iPhone), cloud storage, and PC Windows-explorer integration. It just works. It also means my OneNote notebooks are available everywhere.</p>

<h3><a href="http://lastpass.com">LastPass</a></h3>

<p>I use LastPass Password Manager for its browser integration, always available cloud vault, and cross-device syncing (to my Android).</p>

<h3><a href="http://trello.com">Trello</a></h3>

<p>My wife and I use Trello to manage our household information&mdash;events, shopping, to-do lists, restaurants to eat at, blog posts to write, etc. My wife loves how she can use it easily on her iPhone and get notifications whenever someone changes/adds something. We both like the flexibility it offers and its ease of use. At work, we use it to manage our tasks and work for the team alongside TFS (because, you know, TFS).</p>

<h3><a href="http://www.powerarchiver.com/">PowerArchiver</a></h3>

<p>Yeah, I pay for an archiving software&hellip; it&rsquo;s awesome, easy to use, unzips anything, has Explorer-integration, etc. It was only $23 and they do free upgrades for the Personal edition.</p>

<h3><a href="https://play.google.com/store/apps/details?id=com.snoggdoggler.android.applications.doggcatcher.v1_0&amp;hl=en">Doggcatcher</a>, <a href="http://audible.com">Audible</a>, <a href="http://iheartradio.com">iHeartRadio</a>, <a href="http://spotify.com">Spotify</a></h3>

<p>You have to listen to something while you work, right? Do you just listen to the local radio on your commutes? Podcasts are invaluable for staying current with tech news and listening to books makes it easy to be &ldquo;literate&rdquo; on the go.</p>

<p><strong>Podcasts</strong></p>

<p>I paid for <a href="https://play.google.com/store/apps/details?id=com.snoggdoggler.android.applications.doggcatcher.v1_0&amp;hl=en">Doggcatcher</a> and it&rsquo;s money well spent. It works flawlessly and I listen to podcasts in the car on the way to and from work everyday. Usually I do one day podcasts, one day book, to keep it sane. I also pick and choose the episodes I listen to.</p>

<ul>
<li><a href="https://www.dotnetrocks.com/">.NET Rocks</a></li>
<li><a href="https://twit.tv/shows/this-week-in-tech">This Week in Tech</a></li>
<li><a href="http://www.polygon.com/minimap">Polygon Minimap</a></li>
<li><a href="http://www.giantbomb.com/podcasts/">Giant Bombcast</a></li>
<li><a href="http://maximumfun.org/shows/my-brother-my-brother-and-me">My Brother, My Brother, and Me</a></li>
<li><a href="http://www.thisamericanlife.org/">This American Life</a></li>
</ul>


<p>I listen to <a href="http://audible.com">Audible</a> for books on commutes. I&rsquo;ve been a member for over 6 years and through it own over 100 books and probably have saved myself hundreds of dollars on books. PS. Check out the <a href="http://www.audible.com/series/ref=a_search_c4_1_1_1srSrs_sa?asin=B0085NK3SS">Matthew Corbett series</a>, Edoardo Ballerini is a fucking awesome narrator.</p>

<p>For radio at home, I hooked up my old Android Moto G to a Bluetooth stereo and use <a href="http://iheartradio.com">iHeartRadio</a>.</p>

<p>For streaming music, I subscribe to <a href="http://spotify.com">Spotify</a> that my wife and I share on our devices. I can also use Spotify/iHeartRadio in the basement on my PS4.</p>

<h3>OK Google</h3>

<p>I use OK Google on my phone (Cortana before, on my Windows Phone) to add reminders and to-dos on-the-go.</p>

<h2>Misc</h2>

<h3>Chrome</h3>

<p>I use <a href="http://kamranicus.com/blog/2015/05/21/chrome-multi-user/">supervised user profiles</a> to keep my work separated.</p>

<h3><a href="https://conemu.github.io/">ConEmu</a></h3>

<p>An awesome multi-tabbed customizable command prompt host&mdash;I use it to create shortcuts for Azure Powershell SDK, Visual Studio CMD prompt, Posh-Git, CMD prompt, etc.</p>

<h3><a href="http://regexr.com/">RegExr</a></h3>

<p>An awesome Regular Expression engine in the browser, my go-to Regex reference/tester.</p>

<h3><a href="http://draeton.github.io/stitches/">Stitches</a></h3>

<p>An HTML5-based sprite sheet generator.</p>

<h3><a href="https://emby.media/">Emby</a></h3>

<p>Not work-related but I use Emby (it&rsquo;s free!) to stream media to my consoles and other devices. It has a great web interface for remote viewing too!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Typewriter to Strongly-Type Your Client-Side Models and Services]]></title>
    <link href="http://kamranicus.com/blog/2016/02/04/typewriter/"/>
    <updated>2016-02-04T02:08:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/02/04/typewriter</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve recently discovered <a href="http://frhagn.github.io/Typewriter/index.html">Typewriter for Visual Studio</a>, a T4-style code-generator specifically meant for generating Typescript files. I&rsquo;ve been using it since in all my projects, at work and at home. It&rsquo;s just <strong>so</strong> good. Let me explain what Typewriter does and why it&rsquo;s so awesome.</p>

<!-- more -->


<h2>Setting the stage</h2>

<p>It&rsquo;s 2016. The web app you&rsquo;re working on is a mix of Javascript, C#, and controllers for MVC or Web API. Your solution looks something like this:</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/12835031/1f2c4cfc-cb72-11e5-8f99-d6b3a4af3e83.png" alt="Folder structure" /></p>

<p>You&rsquo;ve got a standard folder structure with a MVC controller and API controller. You want to leverage a client-side library to make it easier to have a dynamic and responsive interface, let&rsquo;s say <a href="http://knockoutjs.com">Knockout.js</a>. You start creating a Knockout view model and you want to bind it to your view. What do you do now at this point for binding the initial data to your view?</p>

<p>Do you&hellip;</p>

<ol>
<li>Serialize the server model into JSON and pass it into your Knockout view model manually</li>
<li>Don&rsquo;t even bother and fetch the data via AJAX when the page loads</li>
</ol>


<p>In either case, you&rsquo;re left with a realization: <strong>I need to pass in my server model so I can use it in my client-side code.</strong> You&rsquo;re left doing something like this:</p>

<p>```js
var TaskListViewModel = function (model) {
   var vm = {};</p>

<p>   vm.name = ko.observable(model.name);
   vm.tasks = ko.observableArray(model.tasks.map(function (t) { return TaskViewModel(t); });</p>

<p>   return vm;
};</p>

<p>$(function () {
  var vm = TaskListViewModel(window.model);</p>

<p>  ko.applyBindings(vm);
});
```</p>

<p>And then passing in your server model, serialized from JSON either via AJAX or embedded in the view:</p>

<p>```html</p>

<script>
window.model = @Html.Raw(JsonConvert.SerializeObject(Model));

// or

$(function () {
  $.getJSON('/api/tasks', function (tasks) {
    var vm = TaskListViewModel(tasks);
    
    ko.applyBindings(vm);
  });
</script>


<p>```</p>

<p>We&rsquo;ve all done something like this because no matter what approach you choose, you have to map the models <em>somewhere</em>. You could use a mapping library like <a href="http://knockoutjs.com/documentation/plugins-mapping.html">ko.mapping</a> to help. But even with help, you still have the same problem:</p>

<blockquote><p>What happens when you change your model in C#?</p></blockquote>

<p>The answer is, &ldquo;I have to go and update all the references in my client-side Javascript.&rdquo; So what do we do? We try to leave it as much alone as we can, preferring not to change things so we can avoid Happy JS Refactoring Funtime.</p>

<h2>Enter Typescript, stage left</h2>

<p>We can address one aspect of this problem using <a href="http://typescriptlang.org">Typescript</a>, the typed superset of Javascript introduced by Microsoft several years ago. My love for Typescript is <a href="http://kamranicus.com/presentations/demystifying-typescript">well-documented</a> and I encourage you to go through that presentation if you haven&rsquo;t already.</p>

<p>Here&rsquo;s one reason why I love it: we can create interfaces that strongly-type our C# models.</p>

<p>```js
interface TaskListViewModel {
  id: number;
  name: string;
  author: string;
  created: Date;
  tasks: TaskViewModel[];
}</p>

<p>interface TaskViewModel {
   order: number;
   canMarkDone: boolean;
   task: Task;
}</p>

<p>interface Task {
  text: string;
  done: boolean;
  created: Date;
  modified: Date;
}
```</p>

<p>Now I&rsquo;ve created an interface that mirrors my serialized C# model representation. So now with Typescript, <strong>anytime</strong> I use a server-side model, I can ensure I never have any problems with misspellings/refactoring or type changes (e.g. &ldquo;author&rdquo; changing from a string to a <code>User</code> model). At compile-time, Typescript will ensure my references are correct.</p>

<p>Using type information, we can strongly type our previous JS view model:</p>

<p>```js
var TaskListViewModel = function (model: TaskListViewModel) {
   var vm = {};</p>

<p>   vm.name = ko.observable<string>(model.name);
   vm.tasks = ko.observableArray<TaskViewModel>(model.tasks.map(function (t) { return TaskViewModel(t); });</p>

<p>   return vm;
};
```</p>

<p>But we still have one problem: how can we avoid the headaches when our server model changes? We <em>still</em> need to update our TS models manually.</p>

<h2>Enter Typewriter, stage right</h2>

<p><a href="http://frhagn.github.io/Typewriter/index.html">Typewriter</a> is a Visual Studio extension that does one thing and does it well: it lets you create <strong>Typescript Template</strong> files. These are <em>basically</em> T4 templates but they&rsquo;re abstracted to the point where it&rsquo;s actually <em>easy</em> to use (sorry T4). When you save your C# files, Typewriter reflects over them and will run the template and generate corresponding Typescript files. This lets you do simple things like mirror types to crazy things like&hellip; generate an entire AJAX web service.</p>

<p>So, using Typewriter, what would the template file look like to mirror our models?</p>

<p>```
namespace TypewriterBlogPost {</p>

<pre><code>$Classes(TypewriterBlogPost.Models.*)[
/**
 * Interface for: $FullName
 */
export interface $Name {
    $Properties[
    $name: $Type;]
}]
</code></pre>

<p>}
```</p>

<p>The syntax of the template file is pretty straightforward, as <a href="http://frhagn.github.io/Typewriter/pages/getting-started.html">explained in the documentation</a>. Let&rsquo;s walk through it.</p>

<p><code>
$Classes(TypewriterBlogPost.Models.*)[
</code></p>

<p>The <code>Classes</code> keyword tells Typewriter to search for all public classes in a file. In parenthesis, you can filter classes by FullName using wildcard syntax. Typewriter also supports Lambda functions to filter by a predicate:</p>

<p><code>
$Classes(x =&gt; x.FullName.Length &gt; 50)[
</code></p>

<p>The open square bracket indicates a repeated block of code of Typescript. We declare an interface since we want to add type safety, not an implementation (although you could, which you&rsquo;ll see next!). You can append another square pair for a separator string if there are > 1 items that match (i.e. multiple classes in a file, multiple properties, multiple methods).</p>

<p>Next, we list the properties using the same syntax. By the way, Typewriter has full Intellisense for all these keywords and variable names.</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/12796507/baabed5c-ca84-11e5-99bf-2079d85dabf0.png" alt="Intellisense" /></p>

<h2>Customize Knockout View Models</h2>

<p>Now that we have our models reflected and auto-syncing with our client-side code, we can do some extra fun stuff to <em>automatically generate Knockout view models.</em></p>

<p>The goal here is to auto-generate a base view model that we can then extend with custom methods, properties, and computed observables.</p>

<p>```js
${</p>

<pre><code>string KnockoutType(Property p) {
    if (p.Type.IsEnumerable) {
        return p.Type.Name.TrimEnd('[',']');
    }

    return p.Type;
}

string KnockoutValue(Property property) {
    var type = KnockoutType(property);

    if (IsEnumerableViewModel(property)) {
        return $"ko.observableArray&lt;Knockout{type}&gt;([])";
    } else if (property.Type.IsEnumerable) {
        return $"ko.observableArray&lt;{type}&gt;([])";
    }

    return $"ko.observable&lt;{type}&gt;()";
}    

bool IsEnumerableViewModel(Property p) {
    string type = KnockoutType(p);

    return p.Type.IsEnumerable &amp;&amp; type.EndsWith("ViewModel");
}
</code></pre>

<p>}
namespace TypewriterBlogPost {</p>

<pre><code>$Classes(*ViewModel)[ 
/**
 * Interface for: $FullName
 */
export interface $Name {
    $Properties[
    $name: $Type;]
}

/**
 * Knockout base view model for $FullName
 */
export class Knockout$Name {        
    $Properties[
    public $name = $KnockoutValue;]

    constructor(model: $Name) {
        this.map(model);
    }

    /**
     * Map $Name model to Knockout view model
     */
    public map(model: $Name) {
        $Properties(x =&gt; !IsEnumerableViewModel(x))[
        this.$name(model.$name);]
        $Properties(x =&gt; IsEnumerableViewModel(x))[
        this.$name(model.$name.map(this.map$Name));]
    }

    $Properties(x =&gt; IsEnumerableViewModel(x))[
    /**
     * Map $KnockoutType equivalent Knockout view model. Override to customize.
     */
    public map$Name(model: $KnockoutType) {
        return new Knockout$KnockoutType(model);
    }]

    /**
     * Returns a plain JSON object with current model properties
     */
    public getModel() {
        return {
            $Properties(x =&gt; !IsEnumerableViewModel(x))[
            $name: this.$name(),]
            $Properties(x =&gt; IsEnumerableViewModel(x))[
            $name: this.$name().map(x =&gt; x.getModel())][,]
        }
    }
}]
</code></pre>

<p>}
```</p>

<p>Oh man! This one&rsquo;s a doozy. All we&rsquo;re really doing is ensuring we recursively map KO view models for collections (we ignore non-ViewModels). We also added a couple convenient helper methods like <code>getModel()</code> that returns a JSON object with the current KO model values. <code>map$Name</code> allows us to customize how we map each collection, for example, to override what view model to use (such as a custom view model).</p>

<p>Typewriter allows you to create &ldquo;helper&rdquo; functions that you can then use in the template. We created ones for parsing out the Knockout types (trimming square brackets).</p>

<p>You might ask why prepend the name with <code>Knockout</code>? So that it won&rsquo;t conflict with the interfaces named after the view models. Since we want to pass in JSON from the server, we still need an interface that represents the server-side view model.</p>

<p>Here&rsquo;s an example of what this template will generate for <code>TaskListViewModel</code>:</p>

<p>```js
namespace TypewriterBlogPost {</p>

<pre><code>/**
 * Interface for: TypewriterBlogPost.ViewModels.TaskListViewModel
 */
export interface TaskListViewModel {

    id: number;
    name: string;
    author: string;
    created: Date;
    tasks: TaskViewModel[];
}

/**
 * Knockout base view model for TypewriterBlogPost.ViewModels.TaskListViewModel
 */
export class KnockoutTaskListViewModel {        

    public id = ko.observable&lt;number&gt;();
    public name = ko.observable&lt;string&gt;();
    public author = ko.observable&lt;string&gt;();
    public created = ko.observable&lt;Date&gt;();
    public tasks = ko.observableArray&lt;KnockoutTaskViewModel&gt;([]);

    constructor(model: TaskListViewModel) {
        this.map(model);
    }

    /**
     * Map TaskListViewModel model to Knockout view model
     */
    public map(model: TaskListViewModel) {

        this.id(model.id);
        this.name(model.name);
        this.author(model.author);
        this.created(model.created);

        this.tasks(model.tasks.map(this.mapTasks));
    }


    /**
     * Map TaskViewModel equivalent Knockout view model. Override to customize.
     */
    public mapTasks(model: TaskViewModel) {
        return new KnockoutTaskViewModel(model);
    }

    /**
     * Returns a plain JSON object with current model properties
     */
    public getModel() {
        return {

            id: this.id(),
            name: this.name(),
            author: this.author(),
            created: this.created(),

            tasks: this.tasks().map(x =&gt; x.getModel())
        }
    }
}
</code></pre>

<p>}
```</p>

<p>Awesome? You bet! So how would I use this in practice? I would just <code>extend</code> the auto-generated code with my custom code!</p>

<p>```js
namespace TypewriterBlogPost {</p>

<pre><code>export class ViewModel extends KnockoutTaskListViewModel {

    constructor(model: TaskListViewModel) {
        super(model);
    }

    addTask() {
        // todo call service
    }
}

// apply KO bindings and use JSON object from server
$(() =&gt; ko.applyBindings(new ViewModel((&lt;any&gt;window).viewModel)));
</code></pre>

<p>}
```</p>

<h2>Strongly-typing your API controllers</h2>

<p>Now that we&rsquo;ve got our view models squared away, how can we leverage Typewriter to help us with our Web API methods? Well, Typewriter comes with an awesome Web API extension that makes it easy to generate strongly-typed service classes.</p>

<p>```js
${</p>

<pre><code>using Typewriter.Extensions.WebApi;

string ReturnType(Method m) =&gt; m.Type.Name == "IHttpActionResult" ? "void" : m.Type.Name;
string ServiceName(Class c) =&gt; c.Name.Replace("Controller", "Service");
string ParentServiceName(Method m) =&gt; ServiceName((Class)m.Parent);
</code></pre>

<p>}</p>

<p>module TypewriterBlogPost {</p>

<pre><code>$Classes(:ApiController)[
export class $ServiceName {
    $Methods[

    // $HttpMethod: $Url
    public static Route$Name = ($Parameters(p =&gt; p.Type.IsPrimitive)[$name: $Type][, ]) =&gt; `$Url`;
    public static $name($Parameters[$name: $Type][, ]): JQueryPromise&lt;$ReturnType&gt; {
        return $.ajax({
            url: $ParentServiceName.Route$Name($Parameters(p =&gt; p.Type.IsPrimitive)[$name][, ]),
            type: '$HttpMethod',
            data: $RequestData
        });
    }]
}]
</code></pre>

<p>}
```</p>

<p>So, let&rsquo;s break it down:</p>

<ol>
<li>Include the WebApi extensions</li>
<li>Create some helper methods to rename the controllers and provide the right return type</li>
<li>For all classes that inherit <code>ApiController</code>

<ol>
<li>Create a service class</li>
<li>For each method:

<ol>
<li>Create a route helper function that returns a URL formatted with the right parameters</li>
<li>Create a JQuery AJAX call that sends a request to the right URL and includes the right request information</li>
</ol>
</li>
</ol>
</li>
</ol>


<p>The <code>TasksController</code> we have defined looks like this:</p>

<p>```csharp
using System;
using System.Collections.Generic;
using System.Linq;
using System.Net;
using System.Net.Http;
using System.Web.Http;
using TypewriterBlogPost.Models;
using TypewriterBlogPost.ViewModels;</p>

<p>namespace TypewriterBlogPost.Controllers
{</p>

<pre><code>public class TasksController : ApiController
{
    private static IList&lt;TaskListViewModel&gt; _taskLists = new List&lt;TaskListViewModel&gt;()
    {
        new TaskListViewModel()
        {
            Name = "Todos",
            Author = "Kamranicus",
            Created = DateTime.Now,
            Id = 1,
            Tasks =
            {
                new TaskViewModel() { Task = new Task() { Text = "Get milk from store" } },
                new TaskViewModel() { Task = new Task() { Text = "Get deli meat", Done = true  } }
            }
        }
    };

    public IEnumerable&lt;TaskListViewModel&gt; GetAll()
    {
        return _taskLists;
    }

    public TaskListViewModel GetById(int id)
    {
        return _taskLists.First(t =&gt; t.Id == id);
    }

    public void Post(int id, Task task)
    {
        var t = GetById(id);

        t.Tasks.Add(new TaskViewModel() { Task = task });        
    }
}
</code></pre>

<p>}
```</p>

<p>A few things to note:</p>

<ol>
<li>To avoid name collisions, I use <code>getAll</code> and <code>getById</code></li>
<li>To use with Typewriter, I return simple types&mdash;using <code>HttpResponseMessage</code> won&rsquo;t allow you to strongly-type the service. However you can still be flexible with errors by throwing <code>HttpExceptions</code> and Web API will serialize your response.</li>
<li>This is terrible code and is for illustrative purposes only</li>
</ol>


<p>What gets generated is what you&rsquo;d expect:</p>

<p>```js
module TypewriterBlogPost {</p>

<pre><code>export class TasksService {


    // get: api/tasks/
    public static RouteGetAll = () =&gt; `api/tasks/`;
    public static getAll(): JQueryPromise&lt;TaskListViewModel[]&gt; {
        return $.ajax({
            url: TasksService.RouteGetAll(),
            type: 'get',
            data: null
        });
    }

    // get: api/tasks/${id}
    public static RouteGetById = (id: number) =&gt; `api/tasks/${id}`;
    public static getById(id: number): JQueryPromise&lt;TaskListViewModel&gt; {
        return $.ajax({
            url: TasksService.RouteGetById(id),
            type: 'get',
            data: null
        });
    }

    // post: api/tasks/${id}
    public static RoutePost = (id: number) =&gt; `api/tasks/${id}`;
    public static post(id: number, task: Task): JQueryPromise&lt;void&gt; {
        return $.ajax({
            url: TasksService.RoutePost(id),
            type: 'post',
            data: task
        });
    }
}
</code></pre>

<p>}
```</p>

<p>Man, <em>how sexy is that?</em> Not only have we ensured our models and view models stay in-sync, our API is also reflected on the client-side so we don&rsquo;t need to worry about hard-coding routes!</p>

<p>Now we can implement our view model method properly:</p>

<p>```js
addTask(id: number, task: Task) {
  return TasksService.post(id, task).then(</p>

<pre><code>() =&gt; toastr.success("Posted new task successfully"));
</code></pre>

<p>}
```</p>

<p>Obviously there&rsquo;s much more you can do such as automatically handling errors, customizing options, creating Angular services, etc.</p>

<h2>So, that&rsquo;s why Typewriter is awesome</h2>

<p>I&rsquo;ve walked through a simple use case of why Typewriter is super useful&mdash;as a developer I&rsquo;m always interested in ways to make my life easier and not worrying about differences between my client and server is always helpful. That&rsquo;s why I love TypeScript and why I love Typewriter. Hope you found this helpful!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Planet Wars AI Competition With C# and Excalibur.js]]></title>
    <link href="http://kamranicus.com/blog/2016/01/25/planet-wars-ai-competition-excaliburjs-csharp/"/>
    <updated>2016-01-25T18:30:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/01/25/planet-wars-ai-competition-excaliburjs-csharp</id>
    <content type="html"><![CDATA[<p><img src="https://zippy.gfycat.com/BraveBlushingImpala.gif" alt="Planet Wars" /></p>

<p>This past weekend <a href="http://twitter.com/erikonarheim">Erik</a> and I built out a <a href="https://github.com/eonarheim/planet-wars-competition">Planet Wars</a> server (written in C#) and an <a href="http://excaliburjs.com">Excalibur.js</a>-powered visualization (written in TypeScript). Planet Wars is an AI competition where you build an AI that competes against another player to control a solar system. A map consists of several planets that have different growth rates and an initial number of ships. You have to send out a &ldquo;fleet&rdquo; of ships to colonize other planets and the player who controls the most planets and has destroyed their opponent&rsquo;s ships wins the game.</p>

<p>At work we are hosting our 6th Code Camp and recently we started hosting an AI competition internally. You can find past competition agents for <a href="https://github.com/eonarheim/AntAICompetition">Ants</a> and <a href="https://github.com/eonarheim/BellTowerEscape">Elevators</a>, for example.</p>

<p>The <a href="https://github.com/eonarheim/planet-wars-competition/tree/master/PlanetWars/Scripts/game">visualization for Planet Wars</a> is fairly simple, made even simpler using the power of <a href="http://excaliburjs.com">Excalibur.js</a>, the engine we work on during our spare time. We basically just use an Excalibur timer to query the status of the game state and update the state of all the actors in the game. For moving the fleets, we just use the <a href="http://excaliburjs.com/docs/api/edge/classes/ex.actioncontext.html">Actor Action API</a>.</p>

<p>For the <a href="https://github.com/eonarheim/planet-wars-competition/tree/master/PlanetWars/Server">game server</a>, we are using a <a href="https://github.com/eonarheim/planet-wars-competition/blob/master/PlanetWars/Server/HighFrequencyTimer.cs">HighFrequencyTimer</a> to run a 30fps server and then clients just send commands via HTTP, so any kind of agent will work like Python, Perl, PowerShell, or whatever! Anything that speaks HTTP can be a client. The server runs in the context of a website so we can easily query the state using a singleton <code>GameManager</code>. This wouldn&rsquo;t work in a load-balanced environment but it doesn&rsquo;t matter since people develop agents locally and we run the simulations on one server at high-speed to produce the results. If you backed the server with a data store, you could replay games but right now there&rsquo;s only an in-memory implementation.</p>

<p>To keep the server and client models in-sync, we use <a href="http://frhagn.github.io/Typewriter/index.html">Typewriter for Visual Studio</a> which is <strong>amazing</strong> and super useful not just for syncing client/server but also generating web clients, interfaces, etc. from C# code. I plan to write a separate post on some Typewriter tips for Knockout.js and Web API.</p>
]]></content>
  </entry>
  
</feed>
