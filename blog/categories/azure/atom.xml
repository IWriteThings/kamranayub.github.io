<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Azure | Kamranicus]]></title>
  <link href="http://kamranicus.com/blog/categories/azure/atom.xml" rel="self"/>
  <link href="http://kamranicus.com/"/>
  <updated>2016-03-06T16:28:04+00:00</updated>
  <id>http://kamranicus.com/</id>
  <author>
    <name><![CDATA[Kamran]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Handling Multiple Origins in CORS Using URL Rewrite]]></title>
    <link href="http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis/"/>
    <updated>2016-03-06T15:50:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/03/06/cors-multiple-origins-iis</id>
    <content type="html"><![CDATA[<p>Here&rsquo;s a quick tip if you&rsquo;re trying to figure out how to handle <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">cross-origin requests (CORS)</a> when you have multiple origins (namely, HTTP and HTTPS). This works in IIS 8.0 and above, including Azure, as long as you have the <a href="http://www.iis.net/downloads/microsoft/url-rewrite">URL Rewrite module</a> installed.</p>

<p>The CORS header looks like this:</p>

<p><code>
Access-Control-Allow-Origin: http://mydomain.com
</code></p>

<p>The spec is very strict. The header can only return a single value and it must be absolutely qualified, which means if you have a site that is served over HTTP and HTTPS (or multiple domains), you need to <em>dynamically</em> build this header in your response. Many tutorials and blog posts say to specify <code>*</code> as the value&mdash;<strong>DO NOT DO THIS!</strong> This means any origin (domain) can embed/request assets from your website. Unless you have hundreds of sites doing this (aka CDN), you should only whitelist the domains that can include resources from your site.</p>

<p>If you are sharing resources with a known number of hosts, the following method will help. If it&rsquo;s a <em>dynamic</em> list, you will need to programmatically add the <code>Access-Control-Allow-Origin</code> header depending on the incoming <code>Origin</code> header&mdash;something I won&rsquo;t cover here.</p>

<p>Rather than messing with C# and modifying outgoing responses what I ended up using was a simple URL rewrite rule, proposed by <a href="http://stackoverflow.com/a/31084390/109458">this Stack Overflow answer</a>. All it does is add a header to the outbound response when the regular expression matches&mdash;in this case, whitelisting only the HTTP and HTTPS version of my domain (or subdomain).</p>

<p>```
&lt;system.webServer>
   <httpProtocol></p>

<pre><code> &lt;customHeaders&gt;
     &lt;add name="Access-Control-Allow-Headers" value="Origin, X-Requested-With, Content-Type, Accept" /&gt;
     &lt;add name="Access-Control-Allow-Methods" value="POST,GET,OPTIONS,PUT,DELETE" /&gt;
 &lt;/customHeaders&gt;
</code></pre>

<p>   </httpProtocol>
   <rewrite></p>

<pre><code>  &lt;outboundRules&gt;
      &lt;clear /&gt;                
      &lt;rule name="AddCrossDomainHeader"&gt;
          &lt;match serverVariable="RESPONSE_Access_Control_Allow_Origin" pattern=".*" /&gt;
          &lt;conditions logicalGrouping="MatchAll" trackAllCaptures="true"&gt;
              &lt;add input="{HTTP_ORIGIN}" pattern="(http(s)?:\/\/((.+\.)?mydomain\.com))" /&gt;
          &lt;/conditions&gt;
          &lt;action type="Rewrite" value="{C:0}" /&gt;
      &lt;/rule&gt;           
  &lt;/outboundRules&gt;
</code></pre>

<p>   </rewrite>
&lt;/system.webServer>
```</p>

<p>This is using special syntax of the URL Rewrite module (<code>RESPONSE_</code>) to add a outgoing response header (dashes replaced with underscores). Then it matches the <em>incoming</em> <code>Origin</code> header, compares the value, and if it matches includes the CORS header with the value of my domain.</p>

<p>That was all I had to do!</p>

<p><strong>Note:</strong> Since I just converted over to always SSL, I no longer need this workaround but multiple origins is pretty common when dealing with CORS so this solution will come in handy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Securing Secrets Using Azure Key Vault and Config Encryption]]></title>
    <link href="http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure/"/>
    <updated>2016-02-24T02:30:00+00:00</updated>
    <id>http://kamranicus.com/blog/2016/02/24/azure-key-vault-config-encryption-azure</id>
    <content type="html"><![CDATA[<p>Secrets. We all have them. I&rsquo;m talking about secrets like your database connection strings, API keys and encryption keys. Where are you storing yours? Are you storing them&hellip;</p>

<ol>
<li>In your application&rsquo;s source code?</li>
<li>In a config file (<code>appSettings</code> or otherwise) checked into source control?</li>
<li>In a database?</li>
<li>In a managed portal, like Azure?</li>
</ol>


<p>I hope you aren&rsquo;t storing them hardcoded. You&rsquo;re probably doing option 2 or a hybrid of options 2-4. Even if you use an external data source, it&rsquo;s hard to escape the need for secrets in local development unless you force your app to rely on having connectivity which makes it hard to work offline.</p>

<p>In this post I&rsquo;m going to provide some suggestions on how to store your secrets better using Azure Key Vault and config file encryption, specifically in the context of Azure but the concepts apply to any hosting environment.</p>

<!-- More -->


<h2>Why bother?</h2>

<p>Some of you might say, &ldquo;It&rsquo;s okay if my secret is in a config file or an environment variable, only an admin can see that.&rdquo; You&rsquo;d assume so, wouldn&rsquo;t you? But I ran into an exploit last year where you could view <strong>ANY</strong> file on the web server using a custom file handler vulnerability (the exploit has since been fixed by the vendor). Just pass in the path you cared about and the handler would helpfully spit out the contents of the file! If your secrets are in cleartext in your configs, are you checking them into source control? Anyone can read those if they have access. If you work in an organization and your code is on the web servers, anyone with access to those servers can see the file system (and therefore, your precious &ldquo;secrets&rdquo;).</p>

<p>You might also (rightfully) say that if an attacker got access to your Azure portal, it&rsquo;s game over anyway. Yes, absolutely. If an app is compromised at the filesystem level where an attacker can upload files, you&rsquo;re pretty much done for. That&rsquo;s why your portal account should have a strong password and have Two-Factor Authentication enabled. If you&rsquo;re using source control integration, that also needs to be protected with the same amount of security to prevent someone from checking in malicious files and having them deployed through automation to the web server&mdash;go and <a href="https://help.github.com/articles/about-two-factor-authentication/">enable TFA for GitHub</a> if you haven&rsquo;t already.  The goal is that we want to avoid storing plaintext secrets on the filesystem and in the portal itself, instead opting to store them in a secure location so that only <strong>our application</strong> has access to them, no one else.</p>

<p>There are more benefits to separating your secrets from your application:</p>

<ul>
<li><strong>Logging</strong> &mdash; Azure Key Vault logs all operations, so if someone did compromise your application, you&rsquo;d have the logs or could monitor them closely for strange actions</li>
<li><strong>Least privilege</strong> &mdash; You can grant a service principal Read-only access so even if the app was compromised, an attacker couldn&rsquo;t change or delete anything (unless they also had access to change the policies in Key Vault)</li>
<li><strong>As-needed access</strong> &mdash; By storing secrets away from your application, you at <em>least</em> guarantee only the application can access secrets whereas anyone with Read access to the portal can see app settings</li>
<li><strong>Defense in depth</strong> &mdash; You&rsquo;re just adding one more layer of security between an attacker and your data</li>
<li><strong>Shared storage</strong> &mdash; If you have multiple apps or services, using a single vault is useful and you can grant access policies at the secret or key level</li>
<li><strong>Encrypted configs</strong> &mdash; Instead of storing secrets in cleartext in source control, I will show you how to encrypt sections of your web.config (and it works in Azure!)</li>
<li><strong>Right thing to do</strong> &mdash; You owe it to your users and to your business to protect their data to the best of your ability</li>
</ul>


<p><a href="http://blogs.msdn.com/b/data_insights_global_practice/archive/2015/09/24/protecting-sensitive-data-with-azure-key-vault.aspx">This article</a> sums it up nicely:</p>

<blockquote><p>One of the key security principals that is implicitly being applied here is to compartmentalize management of privileged data to security domains for which this is appropriate. An instance of Key Vault is used to manage the Twitter keys as a shared resource in the customer&rsquo;s environment, with access granted by whomever manages the Twitter account on an as-needed basis to specific applications and users. Applications are then responsible for managing only their application-specific Key Vault access tokens.</p></blockquote>

<p>With that in mind, let&rsquo;s move on!</p>

<h2>Encryption keys</h2>

<p>The most important secret in your app is probably your <strong>encryption key</strong> (aka &ldquo;keys&rdquo;). This is the skeleton key to your kingdom. If someone got ahold of it, they could unlock your user&rsquo;s data and tarnish your reputation. If your Azure or portal account was compromised (even after Two Factor Auth), would attackers have access to your keys? They would if you stored them in a config or in the portal. So how can you protect this key if none of the options above truly secure it?</p>

<p>Well, what if I told you that <strong>you don&rsquo;t need to know the key</strong>. If nobody knows it, no one can steal it! But how does that work exactly? Magic? Not exactly&hellip;</p>

<h2>Welcome to the vault</h2>

<p>Enter <a href="https://azure.microsoft.com/en-us/services/key-vault/">Azure Key Vault</a>.</p>

<p>Azure Key Vault does two things:</p>

<ul>
<li>It stores encryption &ldquo;keys&rdquo; which <strong>you cannot retrieve</strong> so that you can encrypt and decrypt data, you&rsquo;d use this for user data like PII (Personally Identifiable Information)</li>
<li>It stores &ldquo;secrets&rdquo; which <strong>you can</strong> retrieve, these are things like passwords, API tokens, or other items you pass around</li>
</ul>


<p>A word about how Azure Key Vault stores keys. It&rsquo;s basically the most hardcore thing ever. If you opt for the Premium service tier, your key is stored on <strong>dedicated hardware</strong> called a Hardware Security Module (HSM). I had never heard of these so let me clue you in: they are <strong><a href="https://en.wikipedia.org/wiki/Hardware_security_module">devices</a></strong> where all they do is encrypt and decrypt data and never let the key leave their boundaries. That means, essentially, you present the data you want to encrypt to the device, it encrypts it using a key that <strong>nobody knows</strong>, and spits out the ciphertext for you to store in your system. Azure Key Vault also supports <em>software-protected</em> keys which can operate under the same conditions except they are not stored on a dedicated device. The HSM is validated to be <a href="https://en.wikipedia.org/wiki/FIPS_140-2#Level_2">FIPS 140-2 Level 2</a> compliant (out of 4 levels). What does that mean exactly?</p>

<p>Well, here&rsquo;s Level 1 security:</p>

<blockquote><p>Level 1 provides the lowest level of security. Basic security requirements are specified for a cryptographic module (e.g., at least one Approved algorithm or Approved security function shall be used). No specific physical security mechanisms are required in a Security Level 1 cryptographic module beyond the basic requirement for production-grade components. An example of a Security Level 1 cryptographic module is a personal computer (PC) encryption board.</p></blockquote>

<p>OK, so we&rsquo;re still talking <strong>a dedicated encryption board</strong> to secure keys&hellip; how about Level 2?</p>

<blockquote><p>Security Level 2 improves upon the physical security mechanisms of a Security Level 1 cryptographic module by requiring features that show evidence of tampering, including tamper-evident coatings or seals that must be broken to attain physical access to the plaintext cryptographic keys and critical security parameters (CSPs) within the module, or pick-resistant locks on covers or doors to protect against unauthorized physical access.</p></blockquote>

<p>Jeez. That means there are <em>physical defenses</em> in place on the device to prevent intrusion. We&rsquo;re not even talking intrusion through the network, no, literally these devices are secured so a <strong>human being</strong> cannot access them. Even if it&rsquo;s not Level 4, that&rsquo;s still <em>way</em> more secure than in your App.config or your database or web portal. And even Wikipedia admits that &ldquo;<a href="https://en.wikipedia.org/wiki/Hardware_security_module#Security">very few</a>&rdquo; HSMs are Level 4 validated.</p>

<p>You&rsquo;d think this hardcore security would be pricey right? Not at all. I think the <a href="https://azure.microsoft.com/en-us/pricing/details/key-vault/">$1/key/mo</a> price tag is pretty fair considering the security offered.</p>

<h2>What about secrets?</h2>

<p>OK. So Azure Key Vault is a pretty good solution to our encryption key problem. What about generic secrets, stuff you will need to pass within your application or to external services? Azure Key Vault supports that without any trouble, though they won&rsquo;t be stored on dedicated hardware. They will still be stored separately from your application behind lock and key which is our ultimate goal.</p>

<h2>But even a safe needs a combination, won&rsquo;t the <em>vault</em> require a key?</h2>

<p>Yes! And you are right to point out that it doesn&rsquo;t really solve the secrets problem if the key I need to use to unlock the vault is <em>also</em> stored in my app.config or portal or database. Luckily, there&rsquo;s a way to solve that!</p>

<h2>Certificates to the rescue</h2>

<p>Instead of using the default authentication to Azure AD, a &ldquo;client ID&rdquo; and &ldquo;secret token&rdquo;, we will actually provide a secure X.509 certificate that we&rsquo;ll upload to Azure. Since you can&rsquo;t download the certificate from Azure or access the private key, it will authenticate your application without exposing the key to your vault in a config or portal interface.</p>

<h2>Let&rsquo;s do it!</h2>

<p>I followed these two guides for setting up Key Vault and authenticating using a certificate, so I won&rsquo;t repeat the steps here but I do have several notes below that augment the guides:</p>

<ol>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-get-started/">Getting Started with Azure Key Vault</a></li>
<li><a href="https://azure.microsoft.com/en-us/documentation/articles/key-vault-use-from-web-application">Using Azure Key Vault from a Web Application</a></li>
</ol>


<p>Follow the appendix in guide 2 to generate a certificate to authenticate to Azure AD.</p>

<p>As you work through the guides, reference the notes below.</p>

<h3>PowerShell Cmdlet Changes</h3>

<p>For guide 2, in Azure SDK 2.8+, the cmdlets have changed now:</p>

<ul>
<li><code>New-AzureADApplication</code> is now <code>New-AzureRmADApplication</code></li>
<li><code>New-AzureADServicePrincipal</code> is now <code>New-AzureRmADServicePrincipal</code></li>
</ul>


<p>When executing <code>Set-AzureKeyVaultAccessPolicy</code> make sure to add the switch <code>-PermissionsToSecrets all</code> to grant permissions to manage secrets.</p>

<p><strong>Note:</strong> The article tells you to grant <code>all</code> permissions to both keys and secrets. In reality, for production, you may want to only grant specific rights. See <a href="https://msdn.microsoft.com/en-us/library/dn903607.aspx">this MSDN article</a> for the different access policies.</p>

<h3>Certificates&hellip;?</h3>

<p>If you&rsquo;re like me, you probably find certificates can be confusing. Are you making an SSL cert? Not exactly. <em>Most</em> SSL certs are X.509 certs (not all) but they also can be used to encrypt web traffic. &ldquo;Plain&rdquo; X.509 certs can be used to sign things or encrypt/authenticate, which is what we&rsquo;re doing. If you Google around, you&rsquo;ll see they can be called &ldquo;client certificates&rdquo; or &ldquo;personal&rdquo; certificates. There are two places a cert can be installed (&ldquo;stores&rdquo;), one is the &ldquo;Local Machine&rdquo; store and the other is the &ldquo;Current User&rdquo; store. The machine store can be accessed by <em>any</em> user account, the current user store can only be accessed by the user running the process (usually, you). A &ldquo;cer&rdquo; file is the <strong>public key</strong> for your certificate. You can distribute it to anyone. The &ldquo;pfx&rdquo; file contains <strong>both the private AND public key</strong>. <strong>DO NOT GIVE IT TO ANYONE.</strong> You want the PFX file for yourself only and to import into your PC and into Azure. The PFX file is protected by a password, I recommend a strong one and <em>don&rsquo;t lose it.</em> Rule of thumb: <strong>NEVER let the private key leave your machine. This means don&rsquo;t email it. Yes, this has really happened before.</strong></p>

<h3>Certificate key length</h3>

<p>In guide 2, you create a self-signed certificate. For production should you use a commercially-signed cert? I can&rsquo;t think of a reason why that would add any extra benefit since the <strong>key length</strong> is what matters (if you <em>can</em> think of a reason, I&rsquo;d be interested in hearing it). What I <em>would</em> recommend is generating a certificate with a 4096-bit length key instead of the default 2048 length. In Windows 10 at least, this works:</p>

<p><code>
makecert -sv mykey.pvk -n "cn=KVWebApp" KVWebApp.cer -b 02/23/2016 -e 02/23/2018 -len 4096 -r
</code></p>

<p>If you live in fear, you can buy &ldquo;personal&rdquo; certs from trusted authorities like <a href="https://ssl.comodo.com/personal-authentication.php">Comodo</a> and use that instead.</p>

<h3>Install the certificate</h3>

<p>For guide 2, after generating the certificate you need to install it locally to test Azure Key Vault. If you run your app under IIS and the app pool is <code>ApplicationPoolIdentity</code>, it&rsquo;s best to just <a href="http://www.iis.net/learn/manage/configuring-security/application-pool-identities">change it</a> to run under your account. Trust me, it&rsquo;ll be easier. Since Azure requires the certificate to be in the <code>CurrentUser</code> store, the default app pool runs under a different account (see <a href="http://stackoverflow.com/a/3176253/109458">this StackOverflow post</a>), so you&rsquo;d have to install the cert at the machine level.</p>

<p>In the folder where your cert was generated, right-click the <code>.pfx</code> file and select Install. Enter the password you chose. You can also <a href="http://www.databasemart.com/howto/SQLoverssl/How_To_Import_Personal_Certificate_With_MMC.aspx">follow this guide</a> to do it from the MMC console.</p>

<h2>Alright, so what about local secrets?</h2>

<p>We have the cloud secrets squared away. You <em>could</em> still use Key Vault locally, except you&rsquo;d depend on connectivity (and pay for the usage). Instead, there&rsquo;s something we can do even if we don&rsquo;t end up using Azure Key Vault. We can <strong>encrypt the settings</strong> in the web.config.</p>

<p>I started with <a href="http://eren.ws/2014/02/04/encrypting-the-web-config-file-of-an-azure-cloud-service">this guide</a> to encrypting the configuration sections (but <strong>NOT</strong> <code>appSettings</code>, see below). You <strong>cannot</strong> use the same certificate you generated in the tutorial above (well, maybe you could but you need the <code>-exchange sky</code> switch to <code>makecert</code> and I didn&rsquo;t try that initially so I generated a separate certificate).</p>

<p>There&rsquo;s another thing. You also need to use a different <code>PKCS12ProtectedConfigurationProvider</code>. The one provided <strong>only</strong> searches the <code>LocalMachine</code> certificate store but in Azure, your cert is installed for the current user, so the provider fails to decrypt the config when you try to build your app on Azure because it cannot find the certificate. You need a provider that can specify the <code>StoreLocation</code> of where to load certificates from. For Azure, it must be the <strong>CurrentUser</strong> store.</p>

<p>Here&rsquo;s my modified version:</p>

<script src="https://gist.github.com/kamranayub/eaf4c4e4983ecb2d0b37.js"></script>


<p>I&rsquo;ve also added it to <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider">GitHub</a>. You can download the DLL directly from <a href="https://github.com/kamranayub/PKCS12ProtectedConfigurationProvider/releases/tag/v1.0.1">GitHub</a>. Once done, you can change the entry in the config to:</p>

<p>```</p>

<pre><code>&lt;configProtectedData&gt;
    &lt;providers&gt;
        &lt;add name="CustomProvider"
             thumbprint="xxx"
             storeLocation="LocalMachine"
             type="Pkcs12ProtectedConfigurationProvider.Pkcs12ProtectedConfigurationProvider, PKCS12ProtectedConfigurationProvider, Version=1.0.1.0, Culture=neutral, PublicKeyToken=455a6e7bdbdc9023" /&gt;
    &lt;/providers&gt;
&lt;/configProtectedData&gt;
</code></pre>

<p>```</p>

<p>A few notes:</p>

<ol>
<li>This <strong>is not</strong> the same certificate you generated for Azure AD and Key Vault. This is a separate RSA certificate for use with configuration encryption. You must <em>also</em> upload the PFX for this to Azure.</li>
<li>You will need to install the PKCS12ProtectedConfigurationProvider.dll to the GAC before running the <code>aspnet_regiis</code> command. Just run <code>gacutil -i PKCS12ProtectedConfigurationProvider.dll</code> beforehand.</li>
<li>You will need to reference the custom compiled DLL instead of the one in the guide</li>
<li>I found <a href="http://stackoverflow.com/questions/17189441/web-config-encryption-for-web-sites">this StackOverflow question</a> which asks about encrypting the web.config for Azure web apps. Using the PKCS12 provider, <strong>it works.</strong></li>
</ol>


<h3>Storing secrets outside <code>&lt;appSettings&gt;</code></h3>

<p>I ran into a major hurdle that caused me some grief. It turns out, <strong>YOU CANNOT ENCRYPT THE <code>&lt;appSettings&gt;</code> SECTION!</strong> See <a href="http://stackoverflow.com/questions/15067759/why-cant-i-encrypt-web-config-appsettings-using-a-custom-configprotectionprovid">this SO question</a>.</p>

<p>Other sections are just fine but for whatever reason, IIS just <strong>requires</strong> you to GAC the config provider for it to work. In Azure web apps, we cannot GAC. So what can we do? We can use our <strong>own</strong> config section!</p>

<p>Here&rsquo;s an implementation example of an <code>ISecretsProvider</code> contract and a <code>ConfigSecretsProvider</code> example implementation. You&rsquo;d also create an <code>AzureKeyVaultSecretsProvider</code> probably to handle getting secrets from Azure Key Vault using the code from the guides above.</p>

<script src="https://gist.github.com/kamranayub/eb6518356ac2b2f1a72a.js"></script>


<p>The <code>ConfigSecretsProvider</code> will use environment variables defined in Azure <em>first</em> then fallback to the config. This mirrors how app settings work in Azure.</p>

<p><strong>Note:</strong> Here I am deciding to use only one provider per environment. You might want an implementation that actually uses both. My Key Vault implementation actually uses the <code>ConfigSecretsProvider</code> to find the URL to load the secret for, so that in Azure, the app settings just specify the Key Vault secret URL to load:</p>

<p><img src="https://cloud.githubusercontent.com/assets/563819/13271735/9a0f600a-da5c-11e5-9ff0-106d5e009464.png" alt="App settings in Azure" /></p>

<p>This way, locally I can use the raw value (encrypted) and then in Azure, reference the URL for the secret.</p>

<p>To encrypt the <code>&lt;appSecrets&gt;</code> section, just run the the command (in the same directory as the web.config and using the Visual Studio Command Prompt):</p>

<p><code>
aspnet_regiis -pef appSecrets . -prov CustomProvider
</code></p>

<p>And to decrypt:</p>

<p><code>
aspnet_regiis -pdf appSecrets .
</code></p>

<p>Easy peasy!</p>

<h2>So where are we at?</h2>

<p>If you followed all the guides I linked to and followed the notes, you should have the following:</p>

<ol>
<li>An Azure Key Vault set up with a secret to test with</li>
<li>A certificate that authenticates against Azure AD</li>
<li>A certificate that can encrypt/decrypt your web.config</li>
<li>Both certificates uploaded to Azure through the portal</li>
<li>A <code>&lt;appSecrets&gt;</code> section in your config for local secrets that is encrypted</li>
</ol>


<p>Phew! With all this in place, here&rsquo;s what this gets you:</p>

<ol>
<li>Encryption keys are not known, therefore the <strong>most</strong> an attacker could do if they compromised the application is to decrypt every user through Key Vault which is an audited system and slows them down</li>
<li>Your production secrets are not stored anywhere in your application or source control, local secrets and connection strings are encrypted</li>
<li>No cleartext tokens are used to access Key Vault, instead a signed certificate is used</li>
</ol>


<h2>Implementation notes</h2>

<p>The article above for getting started with a web app is a good place to start but I did a few things to make it easy to test and work with locally.</p>

<ol>
<li>I created an <code>ISecretsProvider</code> interface with two implementations: a config provider (see above) and a Key Vault provider. This also lets me mock for testability.</li>
<li>When I bind the <code>ISecretsProvider</code> for dependency injection, I inspect the current environment and use the appropriate provider (config locally, key vault otherwise)</li>
</ol>


<p>```csharp
// Ninject example</p>

<p>// Secrets provider
kernel.Bind<ISecretsProvider>().ToMethod(ctx =>
{</p>

<pre><code>switch (AppSettings.RuntimeEnvironment)
{
    case RuntimeEnvironment.D:
    case RuntimeEnvironment.P:
        return new AzureKeyVaultSecretsProvider();
    default:
        return new ConfigSecretsProvider();
}
</code></pre>

<p>}).InSingletonScope();
```</p>

<p>Some other thoughts of what you might want to do:</p>

<ul>
<li>Add some logging/telemetry around calls to key vault, such as <a href="https://azure.microsoft.com/en-us/documentation/articles/app-insights-api-custom-events-metrics/#track-dependency">App Insights' track dependency</a></li>
<li>When the Key Vault client supports returning <code>SecureStrings</code>, you could use that to protect secrets in memory</li>
<li>Rotate encryption keys every so often (store the version of the key used on the entities), though this might be pricey for HSM keys</li>
<li>Encrypt secrets before storing them and then decrypt them at runtime (might be overkill)</li>
</ul>


<h3>A word on storing secrets in-memory</h3>

<p>Ideally you would only access secrets as-needed and not store them in memory. But there are some things to consider:</p>

<ul>
<li>If an attacker has compromised your process memory somehow, they&rsquo;ve owned you anyway.</li>
<li>While $0.13/10,000 operations seems cheap, it would add up if you had to call Key Vault <strong>every</strong> time you needed to use a secret</li>
<li>Calling Azure Key Vault does incur some latency, even if it&rsquo;s minimal&mdash;remember that their SLA is 99.9% within 5 seconds so it&rsquo;s possible latency could be pretty poor</li>
<li>At least with the <em>current</em> KeyVault client, it does <strong>not</strong> return secrets as <code>SecureStrings</code>, so it will be in cleartext in memory <em>anyway</em> so what&rsquo;s the difference? (Maybe <a href="https://github.com/Azure/azure-sdk-for-net/issues/1819">they will fix that</a>.)</li>
</ul>


<p>It&rsquo;s up to you but those are my thoughts.</p>

<h2>Troubleshooting</h2>

<p>I ran into a bunch of problems during the writing of this guide. Hopefully these help:</p>

<h3>When I run my app and try to get a secret from Key Vault I get a &ldquo;Keyset does not exist&rdquo; error</h3>

<p>Your app pool/user running the app does not have access to the private key. Follow my advice above to change the app pool identity to your own user account.</p>

<p>I use an app setting to determine where my app is running.</p>

<h3>When I run my app, I get a &ldquo;Bad Key&rdquo; error from the config encryption provider</h3>

<p>You are trying to use the same cert you made for Azure AD, you can&rsquo;t do this. Follow the guide I linked to above to make a new <code>azureconfig</code> cert and import it the same way you did before (to both certificate stores).</p>

<h3>When I build my app in Azure through Continuous Deployment, it&rsquo;s not able to decrypt the web.config</h3>

<ol>
<li>Ensure you uploaded the config PFX file through the portal</li>
<li>Ensure you restarted the application (or Stop then Start)</li>
<li>You can use the Kudu console to run Powershell to check if your cert is uploaded.</li>
<li><code>PS&gt; Set-Location Cert:\CurrentUser\My</code></li>
<li><code>PS&gt; Get-ChildItem</code></li>
<li>Ensure the <code>storeLocation</code> attribute in the web.config is set to <code>CurrentUser</code></li>
<li>Ensure you <strong>are not</strong> encrypting the <code>&lt;appSettings&gt;</code> config section, it&rsquo;s not supported (use the <code>appSecrets</code> workaround above)</li>
<li>Ensure your <code>thumbprint</code> matches the certificate thumbprint</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Azure CDN Origin Pull With Cassette]]></title>
    <link href="http://kamranicus.com/blog/2015/10/10/azure-cdn-cassette/"/>
    <updated>2015-10-10T00:30:00+00:00</updated>
    <id>http://kamranicus.com/blog/2015/10/10/azure-cdn-cassette</id>
    <content type="html"><![CDATA[<p><strong>Update (Feb 2016)</strong>: Updated to use new CDN Profiles.</p>

<p>For the October update for <a href="http://keeptrackofmygames.com">Keep Track of My Games</a> I wanted to offload my web assets to a CDN. Since I&rsquo;m already using <a href="http://azure.com">Microsoft Azure</a> to host the site, I decided to use <a href="https://azure.microsoft.com/en-us/documentation/articles/cdn-how-to-use-cdn/">Azure CDN</a>.</p>

<p>I set it up for &ldquo;Origin Pull&rdquo; which means that instead of uploading my assets to the CDN (Azure Blob storage), you request a file from the CDN and Azure will go and get it from your website and then cache it on their servers.</p>

<p>So as an example:</p>

<p><code>
User requests http://mysite.azureedge.net/stylesheets/foo.png
|
|
CDN: have I cached "stylesheets/foo.png?"
  Yes: Serve content from edge cache (closest to user)
  No: Request http://yourwebsites.com/stylesheets/foo.png and serve
</code></p>

<p>You can read more about <a href="https://azure.microsoft.com/en-us/documentation/articles/cdn-create-new-endpoint/">how to set up origin pull in Azure CDN</a>. In my case, I used &ldquo;Custom Origin&rdquo; of &ldquo;<a href="http://keeptrackofmygames.com">http://keeptrackofmygames.com</a>&rdquo;.</p>

<h2>Using CDN with Cassette</h2>

<p>I use the .NET library <a href="http://getcassette.com">Cassette</a> for bundling &amp; minification for KTOMG&mdash;when I started KTOMG there was no Microsoft provided option and Cassette has been really stable.</p>

<p>It works pretty much as you&rsquo;d expect:</p>

<ul>
<li>Define &ldquo;bundles&rdquo; which are sets of scripts/stylesheets</li>
<li>Render bundles onto page(s)</li>
<li>If debug mode, render individually otherwise minify and concatenate</li>
</ul>


<p>By default, Cassette will render URLs like this in your source code:</p>

<p>In debug mode:</p>

<p>```
Bundle: ~/Content/core</p>

<ul>
<li>/cassette.axd/asset/Content/bootstrap.css?hash</li>
<li>/cassette.axd/asset/Content/site.css?hash</li>
<li>/cassette.axd/asset/Content/app.css?hash
```</li>
</ul>


<p>And in production:</p>

<p><code>
/cassette.axd/stylesheet/{hash}/Content/core
</code></p>

<p>But if we want to serve assets over the CDN, we need to plug in our special CDN URL prefix&mdash;not only for script/stylesheet references but also references to images <em>in</em> those files.</p>

<p>Luckily, Cassette provides a facility to modify generated URLs by letting you register a <code>IUrlGenerator</code>. Here&rsquo;s my full implementation of this for my CDN:</p>

<script src="https://gist.github.com/kamranayub/2da4ccfec3e7812c8367.js"></script>


<p>As you can see, I register a custom <code>IUrlGenerator</code> and a custom <code>IUrlModifier</code>. The default <code>IUrlModifider</code> is Cassette&rsquo;s <code>VirtualDirectoryPrepender</code> and it just prepends &ldquo;/&rdquo; to the beginning of every URL but in our case we want to conditionally prepend the Azure CDN endpoint in production.</p>

<p>In production, this will produce the following output:</p>

<p><code>
https://mysite.azureedge.net/cassette.axd/stylesheet/{hash}/Content/core
</code></p>

<p>To allow local debugging and CDN in production I just use an app setting in the web.config. In Azure, I also add an application setting (<code>CdnUrl</code>) through the portal in my production slot with the correct CDN URL and voila&mdash;all my assets will now be served over CDN.</p>

<h3>Notes</h3>

<ul>
<li><p>Azure CDN does not yet support HTTPS for custom origin domains. So if you want to serve content over <a href="http://static.yoursite.com">http://static.yoursite.com</a> you can&rsquo;t serve it over HTTPS because Azure doesn&rsquo;t allow you to upload or set a SSL certificate to use and insteads uses their own certificate which is not valid for your domain. <a href="http://feedback.azure.com/forums/169397-cdn/suggestions/1332683-allow-https-for-custom-cdn-domain-names">Vote up the UserVoice issue</a> on this.</p></li>
<li><p>Azure CDN will serve your entire site, not just assets. There may be a way to prevent browsing the site over CDN (i.e. &ldquo;assets only&rdquo;). <a href="https://social.msdn.microsoft.com/Forums/en-US/azurecdn/thread/055bb85f-0bde-4710-8c4d-bce122d5938c/">See this MSDN thread</a>. I have not yet implemented the proposed fix.</p></li>
<li><p>I am choosing <strong>not</strong> to point my entire domain to the CDN. Some folks choose to serve their entire site over the CDN which is definitely something you can do. However, in my case, I didn&rsquo;t want to do that. If you instead chose to point your domain to the CDN endpoint, you don&rsquo;t need to do any of this&mdash;<strong>everything</strong> will be served over the CDN. However, note that if your site is highly dynamic this results in a double hop&mdash;once to CDN, once to the origin, so you will not see much benefit unless your entire site is mostly static.</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting WebSockets to Work on Windows Azure]]></title>
    <link href="http://kamranicus.com/blog/2014/02/09/websockets-on-windows-azure/"/>
    <updated>2014-02-09T03:52:48+00:00</updated>
    <id>http://kamranicus.com/blog/2014/02/09/websockets-on-windows-azure</id>
    <content type="html"><![CDATA[<p>I was banging my head against the wall for the past hour or so wondering why I was falling back to XHR polling when I deployed my Node.js application to Azure. I&rsquo;m using socket.io and everything looks like it&rsquo;s in order, works locally, etc. It was failing with a WebSocket handshake error.</p>

<p>What I saw in the Chrome developer console was something like:</p>

<pre><code>Error during WebSocket handshake: Unexpected response code: 502
</code></pre>

<p>In my Azure Node.js console (<code>azure site log tail SITENAME</code>), I was seeing <code>EPIPE</code> errors.</p>

<p>It turns out, this little tidbit from the <a href="http://blogs.msdn.com/b/windowsazure/archive/2013/11/14/introduction-to-websockets-on-windows-azure-web-sites.aspx">original Windows Azure blog post</a> on Web Sockets did the trick.</p>

<p>Modify your <strong>web.config</strong> and add:</p>

<pre><code>&lt;webSocket enabled="false" /&gt;
</code></pre>

<p>To your <code>system.webServer</code> configuration. Also, another good point in that blog post is to use SSL, since you get SSL for free with a <code>*.azurewebsites.net</code> site.</p>

<p>Hope this helps someone else out there. This should be added to the <a href="http://www.windowsazure.com/en-us/documentation/articles/web-sites-nodejs-chat-app-socketio/">official Azure tutorial</a> on using web sockets with Node.js.</p>
]]></content>
  </entry>
  
</feed>
